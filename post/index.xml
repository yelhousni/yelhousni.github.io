<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts | يوسف</title>
    <link>/post/</link>
      <atom:link href="/post/index.xml" rel="self" type="application/rss+xml" />
    <description>Posts</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><lastBuildDate>Mon, 06 Oct 2025 00:00:00 +0000</lastBuildDate>
    <image>
      <url>/img/icon-192.png</url>
      <title>Posts</title>
      <link>/post/</link>
    </image>
    
    <item>
      <title>A note on implementing subgroup membership using the Tate pairing</title>
      <link>/post/subgroup/</link>
      <pubDate>Mon, 06 Oct 2025 00:00:00 +0000</pubDate>
      <guid>/post/subgroup/</guid>
      <description>&lt;p&gt;The paper &amp;ldquo;Subgroup membership testing on elliptic curves via the Tate pairing&amp;rdquo; by Dmitrii Koshelev (&lt;a href=&#34;https://eprint.iacr.org/2022/037.pdf&#34;&gt;https://eprint.iacr.org/2022/037.pdf&lt;/a&gt;) is a cute result. Let $E/F_p$ be an elliptic curve of order $N = c\cdot r$, with prime integer $r$. To check that a point $P \in E$ is of order $r$, the naive method is to check that $[r]P = \mathcal{O}$. The paper shows that, given the group structure $E \cong Z_{e_1} \bigoplus Z_{e_2 \cdot r}$ and $e_2 \mid p-1$ ($c$ being $e_1\cdot e_2$), it is sufficient to check that the Tate pairings:&lt;/p&gt;
&lt;p&gt;$$
f_{e_1,P_1}(P)^{(p-1)/e_1} = 1 \quad \text{and}\quad f_{e_2,P_2}(P)^{(p-1)/e_2} = 1
$$&lt;/p&gt;
&lt;p&gt;where $P_1$ and $P_2$ are points on $E$ of orders $e_1$ and $e_2$ respectively.&lt;/p&gt;
&lt;p&gt;$E$ is not necessarily pairing-friendly. Pairing-friendliness just means that the embedding degree $k$ is small enough to have fast arithmetic and big enough to have good security (e.g. $k=12$ for BLS12 and BN curves). Here $k=1$ and we only care about performance. To compute these pairings, we need to compute:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;the Miller functions $f_{e_i,P_i}$&lt;/li&gt;
&lt;li&gt;the final exponentiations by $(p-1)/e_i$&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;The whole idea of the paper is that when $e_i$ are small, these two steps become very efficient to implement.&lt;/p&gt;
&lt;h4 id=&#34;step-2&#34;&gt;Step 2&lt;/h4&gt;
&lt;p&gt;Let us start with step 2. Given $f\in F_p$, checking that $f^{(p-1)/e_i} =_? 1$ is equivalent to checking if $f$ is an $e_i$-th residue in $F_p$, i.e. $\exists z \in F_p$ s.t. $z^{e_i} = f \pmod p$. This is known as Euler criterion. For small $e_i$, this can be performed more efficiently than exponentiation, by using Euclidean algorithms. The power residue symbol satisfy similar relations to the GCD and hence one can adapt GCD algorithms to compute power residue symbols. For $e_i = 2$, this is known as the Legendre symbol and can be computed efficiently using the binary GCD algorithm (see &lt;a href=&#34;https://github.com/pornin/x25519-cm0?tab=readme-ov-file#legendre-symbol&#34;&gt;Pornin&amp;rsquo;s algorithm&lt;/a&gt; and &lt;a href=&#34;https://github.com/Consensys/gnark-crypto/pull/704&#34;&gt;gnark-crypto implementation&lt;/a&gt; by Arya). For bigger $e_i \leq 16$, there are similar algorithms — although less &amp;ldquo;CPU-friendly&amp;rdquo; than the binary-GCD. However, one can always resolve to exponentiations.&lt;/p&gt;
&lt;h4 id=&#34;step-1&#34;&gt;Step 1&lt;/h4&gt;
&lt;p&gt;Computing Miller functions is done through Miller loops. For small $e_i$, we can explicitly give the formulas. For example when $e_i=2$, the paper states that $f_{e_i,P_i} = X - X_{P_i}$ which is true when the curve is given in short Weierstrass form $E_{sw}: Y^2=X^3+AX+B$. When $e_i=1$, $f_i=1$ trivially. When $e_i=2^m$, the paper gives the formula in page 5.&lt;/p&gt;
&lt;h3 id=&#34;discussion&#34;&gt;Discussion&lt;/h3&gt;
&lt;p&gt;I believe that the result is significantly performant only when $e_1=e_2=2$, in which case we can compute the Legendre symbol efficiently using the binary-GCD algorithm. For other cases it is still moderately fast using exponentiations, or someone has to implement efficient Euclidean-type higher power residue symbols.&lt;/p&gt;
&lt;p&gt;Now let us focus on the case $e_1=e_2=2$. This happens for the curve &lt;a href=&#34;https://eprint.iacr.org/2021/1152.pdf&#34;&gt;Bandersnatch&lt;/a&gt; used in Verkle trie. It is mostly efficient when given in twisted Edwards form $E_{ed}: ax^2+y^2=1+dx^2y^2$. So to implement this test with input points $(x,y)\in E_{ed}$, we need to map $(x,y)$ to $(X,Y) \in E_{sw}$. The formula is:&lt;/p&gt;
&lt;p&gt;$$
X = (\frac{a-d}{4})\cdot(\frac{1+y}{1-y}) + \frac{a+d}{6}
$$&lt;/p&gt;
&lt;p&gt;and we don&amp;rsquo;t need the $Y$ coordinate.&lt;/p&gt;
&lt;p&gt;To avoid inverses we use the fact that $(\frac{1/x}{p})&lt;em&gt;2 = (\frac{x}{p})&lt;em&gt;2$. Thus, $f&lt;/em&gt;{2,P_i} = X - X&lt;/em&gt;{P_i}$ becomes:&lt;/p&gt;
&lt;p&gt;$$
12(a-d)^2(1-y)[(5a - d - 12X_{P_i}) + (a - 5d + 12X_{P_i})y]
$$&lt;/p&gt;
&lt;p&gt;or equivalently&lt;/p&gt;
&lt;p&gt;$$
t_2 (1-y)(t_1 + t_0y)
$$&lt;/p&gt;
&lt;p&gt;with $t_2=12(a-d)^2$, $t_1=5a - d - 12X_{P_i}$ and $t_0=a - 5d + 12X_{P_i}$ some pre-computed constants.&lt;/p&gt;
&lt;p&gt;For Bandersnatch implementers, they just need to take this last formula with:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$X_{P_1} = \texttt{0x23e93c143a3aa62dfef158aabe40ed250530ac9369509c984891a87e04178ed3}$&lt;/li&gt;
&lt;li&gt;$X_{P_2} = \texttt{0x5de00fbdcf0964d2188e44aec311d927af0f7e94e94fca97c891a87d84178ed1}$&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;which leads, for the first point, to:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$t_0=1$&lt;/li&gt;
&lt;li&gt;$t_1=1$&lt;/li&gt;
&lt;li&gt;$t_2=\texttt{0x384d1c153c878eea316b96e5c340cf6abd025b636bd74122926c66eb6fa86d15}$&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;and, for the second, to:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;$t_0=\texttt{0x636b1e56f54c03e873dd6068f2f238776f43b4a3d72a357835d2fc15ba90cdea}$&lt;/li&gt;
&lt;li&gt;$t_1=\texttt{0x108288fc3451795fbf5c779f16af9f8de479ef5f28d42686ca2d03e9456f321d}$&lt;/li&gt;
&lt;li&gt;$t_2=\texttt{0x34f9acec8bf92f766108eca94020963ae3496e2743876768b74534c34ef9473e}$&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;A full implementation in gnark-crypto can be found here: &lt;a href=&#34;https://github.com/Consensys/gnark-crypto/pull/708&#34;&gt;https://github.com/Consensys/gnark-crypto/pull/708&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Cipher Challenge 2025 — UM6P</title>
      <link>/post/cipherchallenge/</link>
      <pubDate>Sat, 12 Apr 2025 00:00:00 +0000</pubDate>
      <guid>/post/cipherchallenge/</guid>
      <description>&lt;p&gt;I helped organize the Cipher Challenge 2025 — Cryptography Edtion held at the
University Mohammed VI Polytechnique (UM6P) in Rabat, Morocco. The event took
place on April 12 and 13, 2025, and was a great success, attracting
participants from various universities and institutions in Morocco.&lt;/p&gt;
&lt;p&gt;My contribution was twofold: Prior to the event, I created (most of) the
challenges and also assisted in grading the students. On April the 12th, I gave
a keynote talk on Modern &amp;ldquo;Applications of Cryptography&amp;rdquo;. The material I
contributed can be found at: &lt;a href=&#34;https://cipherchallenge.github.io/&#34;&gt;https://cipherchallenge.github.io/&lt;/a&gt;.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Fake GLV</title>
      <link>/post/fakeglv/</link>
      <pubDate>Fri, 20 Sep 2024 00:00:00 +0000</pubDate>
      <guid>/post/fakeglv/</guid>
      <description>&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt; _____     _           ____ _ __     __
|  ___|_ _| | _____   / ___| |\ \   / /
| |_ / _` | |/ / _ \ | |  _| | \ \ / /
|  _| (_| |   &amp;lt;  __/ | |_| | |__\ V /
|_|  \__,_|_|\_\___|  \____|_____\_/
&lt;/code&gt;&lt;/pre&gt;&lt;h2 id=&#34;you-dont-need-an-efficient-endomorphism-to-implement-glv-like-scalar-multiplication-in-snark-circuits&#34;&gt;You don&amp;rsquo;t need an efficient endomorphism to implement GLV-like scalar multiplication in SNARK circuits&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;../post/fakeglv/#Introduction&#34;&gt;Introduction&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;../post/fakeglv/#Other-applications&#34;&gt;Other applications&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;../post/fakeglv/#Background&#34;&gt;Background&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;../post/fakeglv/#The-fake-GLV-trick6&#34;&gt;The fake GLV trick&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;../post/fakeglv/#Implementation7&#34;&gt;Implementation&lt;/a&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;../post/fakeglv/#Benchmark&#34;&gt;Benchmark&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;../post/fakeglv/#Comparison&#34;&gt;Comparison&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;
&lt;p&gt;P-256, also known as secp256r1 and prime256v1, is a 256-bit prime field Weierstrass curve standardized by the NIST. It is widely adopted in internet systems, which explains its myriad use cases in platforms such as TLS, DNSSEC, Apple’s Secure Enclave, Passkeys, Android Keystore, and Yubikey. The key operation in elliptic curves based cryptography is the scalar multiplication. When the curve is equipped with an efficient endomorphism it is possible to speed up this operation through the well-known &lt;a href=&#34;https://www.iacr.org/archive/crypto2001/21390189.pdf&#34;&gt;GLV&lt;/a&gt; algorithm. P-256 does unfortunately not have an efficient endomorphism (see &lt;a href=&#34;https://neuromancer.sk/std/nist/P-256&#34;&gt;parameters&lt;/a&gt;) to enjoy this speedup.&lt;/p&gt;
&lt;p&gt;Verifying ECDSA signatures on Ethereum through precompiled contracts, i.e. smart contracts built into the Ethereum protocol (there are only 9) is only possible with the &lt;em&gt;secp256k1&lt;/em&gt; curve and not the P-256.
Verifying ECDSA signatures on P-256 requires computing scalar multiplications in Solidity and is especially useful for smart-contract wallets, enabling hardware-based signing keys and safer, easier self-custody. Different solutions can bring P-256 signatures on-chain. There are primarily three interesting approaches: (zk)-SNARK based verifiers, smart contract verifiers (e.g. &lt;a href=&#34;https://eprint.iacr.org/2023/939.pdf&#34;&gt;[Dubois23]&lt;/a&gt;, &lt;a href=&#34;#ZgotmplZ&#34;&gt;Ledger/FCL&lt;/a&gt; (deprecated), &lt;a href=&#34;https://github.com/get-smooth/crypto-lib&#34;&gt;smoo.th/SCL&lt;/a&gt; and &lt;a href=&#34;https://daimo.com/blog/p256verifier&#34;&gt;daimo/p256verifier&lt;/a&gt;), and native protocol precompiles (&lt;a href=&#34;https://github.com/ethereum/RIPs/blob/master/RIPS/rip-7212.md&#34;&gt;EIP/RIP 7212&lt;/a&gt;).&lt;/p&gt;
&lt;p&gt;Using SNARK (succinctness) properties, provides a great way to reduce gas cost for computation on Ethereum (e.g. ~232k gas for &lt;a href=&#34;https://eprint.iacr.org/2016/260.pdf&#34;&gt;Groth16&lt;/a&gt;, ~285k gas for &lt;a href=&#34;https://eprint.iacr.org/2019/953.pdf&#34;&gt;PLONK&lt;/a&gt; and ~185k gas for &lt;a href=&#34;https://eprint.iacr.org/2021/1167&#34;&gt;FFLONK&lt;/a&gt;). This is very competitive with (and sometimes better that) the currently gas-optimal smart contract verifier. Moreover one can batch many ECDSA verifications in a single proof, amortizing thus the gas cost. However verifying P-256 signatures in a SNARK circuit can be very expensive i.e. long proving time. This is because the field where the points on the P-256 curve lie is different than the field where the SNARK computation is usually expressed. To be able to verify the proof onchain through the procompile the SNARK field needs to be the &lt;a href=&#34;https://hackmd.io/@jpw/bn254&#34;&gt;BN254&lt;/a&gt; scalar field. Different teams tried to implement the ECDSA verification on P-256 in a BN254 SNARK circuit efficiently. Among these: &lt;a href=&#34;https://github.com/zkwebauthn/webauthn-halo2&#34;&gt;zkwebauthn/webauthn-halo2&lt;/a&gt;, &lt;a href=&#34;https://github.com/zkwebauthn/webauthn-circom&#34;&gt;https://github.com/zkwebauthn/webauthn-circom&lt;/a&gt; and &lt;a href=&#34;https://github.com/privacy-scaling-explorations/circom-ecdsa-p256&#34;&gt;PSE/circom-ecdsa-p256&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;If P-256 had an efficient endomorphism we could have optimized the proving time a great deal!&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;In this note we show a way to implement a GLV-like scalar multiplications in-circuit without having an efficient endomorphism.&lt;/p&gt;
&lt;h3 id=&#34;other-applications&#34;&gt;Other applications&lt;/h3&gt;
&lt;ul&gt;
&lt;li&gt;This technique can be applied to any elliptic curve without an efficient endomorphism (e.g. &lt;a href=&#34;https://en.wikipedia.org/wiki/Curve25519&#34;&gt;Curve25519&lt;/a&gt;, &lt;a href=&#34;https://en.wikipedia.org/wiki/P-384&#34;&gt;P-384&lt;/a&gt;, MNT-753 (&lt;a href=&#34;https://coinlist.co/build/coda/pages/MNT4753&#34;&gt;k=4&lt;/a&gt;, &lt;a href=&#34;https://coinlist.co/build/coda/pages/MNT6753&#34;&gt;k=6&lt;/a&gt;), &lt;a href=&#34;https://docs.starknet.io/architecture-and-concepts/cryptography/stark-curve/&#34;&gt;STARK curve&lt;/a&gt;, &lt;a href=&#34;https://eprint.iacr.org/2024/869&#34;&gt;$\mathcal{B}$ of &amp;ldquo;cycle5&amp;rdquo;&lt;/a&gt;, &amp;hellip;). See this &lt;a href=&#34;https://neuromancer.sk/std/&#34;&gt;database&lt;/a&gt; for other curves.&lt;/li&gt;
&lt;li&gt;This would question the choice of &lt;a href=&#34;https://eprint.iacr.org/2021/1152&#34;&gt;Bandersnatch&lt;/a&gt; (&lt;em&gt;an embedded endomorphism-equipped curve over BLS12-381&lt;/em&gt;) over &lt;a href=&#34;https://github.com/zkcrypto/jubjub&#34;&gt;Jubjub&lt;/a&gt; (&lt;em&gt;an embedded curve over BLS12-381 without endomorphism&lt;/em&gt;) for &lt;a href=&#34;https://verkle.info/&#34;&gt;Ethereum Verkle trees&lt;/a&gt;.&lt;/li&gt;
&lt;li&gt;This can speedup ECDSA verification in &lt;a href=&#34;https://docs.cairo-lang.org/hello_starknet/signature_verification.html&#34;&gt;Starknet&lt;/a&gt; and &lt;a href=&#34;https://www.cairo-lang.org/&#34;&gt;Cairo&lt;/a&gt; (through the &lt;a href=&#34;https://docs.starknet.io/architecture-and-concepts/cryptography/stark-curve/&#34;&gt;STARK curve&lt;/a&gt;).&lt;/li&gt;
&lt;li&gt;This can speedup natively the folding step (à la Nova) of Ed25519 signatures through the 2-cycles proposed &lt;a href=&#34;https://moderncrypto.org/mail-archive/curves/2024/001050.html&#34;&gt;here&lt;/a&gt; by Aurore Guillevic.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;background&#34;&gt;Background&lt;/h2&gt;
&lt;h3 id=&#34;standard-scalar-multiplication&#34;&gt;Standard scalar multiplication&lt;/h3&gt;
&lt;p&gt;Let $E$ be an elliptic curve defined over the prime field $\mathbb{F}_p$ and let $r$ be a prime divisor of the curve order #$E(\mathbb{F}_p)$ (i.e. the number of points).
Let $s \in \mathbb{F}_r$ and $P(x,y) \in E(\mathbb{F}_p)$, we are interested in proving scalar multiplication $s\cdot P$ over the $r$-torsion subgroup of $E$, denoted $E[r]$ (i.e. the subset of points of order $r$).&lt;/p&gt;
&lt;p&gt;The simplest algorithm is the standard left-to-right &lt;em&gt;double-and-add&lt;/em&gt;:&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;INPUT: s = (s_{t−1},..., s_1, s_0), P ∈ E(Fp).
OUTPUT: sP.
1. Q ← ∞.
2. For i from t−1 downto 0 do
    2.1 Q ← 2Q.
    2.2 If s_i = 1 then Q ← Q + P.
3. Return(Q).
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;If/else branching is not possible in SNARK circuits so this is replaced by constant window table lookups inside the circuit. This can be achieved using polynomials which vanish at the constants that aren’t being selected, i.e. a 1-bit table lookup &lt;code&gt;Q ← s_i * Q + (1 - s_i) * (Q+P)&lt;/code&gt;. Hence this double-and-add algorithm requires $t$ doublings, $t$ additions and $t$ 1-bit table lookup.
This can be extended to &lt;em&gt;windowed&lt;/em&gt; double-and-add, i.e. scanning more than a bit per iteration using larger window tables, but the multiplicative depth of the evaluation increases exponentially. We use affine coordinates for doubling/adding points because inverses cost as much as multiplications, i.e. instead of checking that $1/x$ is $y$ we provide $y$ out-circuit and check in-circuit that $x\cdot y = 1$. However since we start with $Q ← ∞$ it is infeasible to avoid conditional branching since affine formulas are incomplete. Instead, we scan the bits right-to-left and assume that the first bit &lt;code&gt;s_0&lt;/code&gt; is 1 (so that we start at &lt;code&gt;Q ← P&lt;/code&gt;), we double the input point &lt;code&gt;P&lt;/code&gt; instead of the accumulator &lt;code&gt;Q&lt;/code&gt; in this algorithm and finally conditionally subtract (using the 1-bit lookup) &lt;code&gt;P&lt;/code&gt; if &lt;code&gt;s_0&lt;/code&gt; was 0.&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;INPUT: s = (s_{t−1},..., s_1, s_0), P ∈ E(Fp).
OUTPUT: sP.
1. Q ← P.
2. For i from 1 to t−1 do
    2.1 If s_i = 1 then Q ← Q + P.
    2.2 P ← 2P.
3. if s_0 = 0 then Q ← Q - P
4. Return(Q).
&lt;/code&gt;&lt;/pre&gt;&lt;h3 id=&#34;glv-scalar-multiplication&#34;&gt;GLV scalar multiplication&lt;/h3&gt;
&lt;p&gt;However it is well known that if the curve is equipped with an efficient endomorphism then there exists a faster algorithm known as &lt;a href=&#34;https://www.iacr.org/archive/crypto2001/21390189.pdf&#34;&gt;[GLV]&lt;/a&gt;.
:::info
&lt;strong&gt;Example 1 :&lt;/strong&gt; suppose that $E$ has Complex Multiplication (CM) with discrimant $-D=-3$, i.e. $E$ is of the form $y^2=x^3+b$, with $b \in \mathbb{F}_p$. This is the case of &lt;code&gt;BN254&lt;/code&gt;, &lt;code&gt;BLS12-381&lt;/code&gt; and &lt;code&gt;secp256k1&lt;/code&gt; elliptic curves used in Ethereum. There is an efficient endomorphism $\phi: E \rightarrow E$ defined by $(x,y)\mapsto (\omega x,y)$ (and $\mathcal{O} \mapsto \mathcal{O}$) that acts on $P \in E[r]$ as $\phi(P)=\lambda \cdot P$. Both $\omega$ and $\lambda$ are cube roots of unity in $\mathbb{F}_p$ and $\mathbb{F}_r$ respectively, i.e. $\omega^2+\omega+1 \equiv 0 \pmod p$ and $\lambda^2+\lambda+1 \equiv 0 \pmod r$.
:::
:::info
&lt;strong&gt;Example 2 :&lt;/strong&gt; suppose that $E$ has Complex Multiplication (CM) with discrimant $-D=-8$, meaning that the endomorphism ring is $\mathbf{Z}[\sqrt{−2}]$. This is the case of the &lt;code&gt;Bandersnatch&lt;/code&gt; elliptic curves specified in Ethereum Verkle trie. There is an efficient endomorphism $\phi: E \rightarrow E$ whose kernel is generated by a 2-torsion point. The map can be found by looking at 2-isogeneous curves and applying Vélu&amp;rsquo;s formulas. For Bandersnatch it is defined by $(x,y)\mapsto (u^2\cdot \frac{x^2+wx+t}{x+w},u^3\cdot y\cdot \frac{x^2+2wx+v}{(x+w)^2})$ for some constants $u,v,w,t$ (and $\mathcal{O} \mapsto \mathcal{O}$) that acts on $P \in E[r]$ as $\phi(P)=\lambda \cdot P$ where $\lambda^2+2 \equiv 0 \pmod r$.
:::
The GLV algorithm starts by decomposing $s$ as $s = s_0 + \lambda s_1$ and then replacing the scalar multiplication $s \cdot P$ by $s_0 \cdot P + s_1 \cdot \phi(P)$. Because $s_0$ and $s_1$ are guaranteed to be $\leq \sqrt{r}$ (see Sec.4 of &lt;a href=&#34;https://www.iacr.org/archive/crypto2001/21390189.pdf&#34;&gt;[GLV]&lt;/a&gt; and Sec.4 of &lt;a href=&#34;https://eprint.iacr.org/2015/565.pdf&#34;&gt;[FourQ]&lt;/a&gt; for an optimization trick), we can halve the size of the for loop in the double-and-add algorithm. We can then scan simultaenously the bits of $s_0$ and $s_1$ and apply the &lt;a href=&#34;https://crypto.stackexchange.com/questions/99975/strauss-shamir-trick-on-ec-multiplication-by-scalar&#34;&gt;Strauss-Shamir trick&lt;/a&gt;. This results in a significant speed up but only when an endomorphism is available. For example the left-to-right double-and-add would become:&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;INPUT: s and P ∈ E(Fp).
OUTPUT: sP.
1. Find s1 and s2 s.t. s = s1 + 𝜆 * s2 mod r
    1.1 let s1 = (s1_{t−1},..., s1_1, s1_0)
    1.2 and s2 = = (s2_{t−1},..., s2_1, s2_0)
2. P1 ← P, P2 ← 𝜙(P) and Q ← ∞.
3. For i from t−1 downto 0 do
    3.1 Q ← 2Q.
    3.2 If s1_i = 0 and s2_i = 0 then Q ← Q.
    3.3 If s1_i = 1 and s2_i = 0 then Q ← Q + P1.
    3.4 If s1_i = 0 and s2_i = 1 then Q ← Q + P2.
    3.5 If s1_i = 1 and s2_i = 1 then Q ← Q + P1 + P2.
4. Return(Q).
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;Using the efficient endomorphism in-circuit is also possible (see &lt;a href=&#34;https://eprint.iacr.org/2019/1021.pdf&#34;&gt;[Halo, Sec. 6.2 and Appendix C]&lt;/a&gt; or &lt;a href=&#34;https://github.com/Consensys/gnark/blob/ea53f373f45d2f9ad9cc1639c34359a35f771191/std/algebra/emulated/sw_emulated/point.go#L530&#34;&gt;[gnark implementation]&lt;/a&gt; for short Weierstrass curves and &lt;a href=&#34;https://github.com/zhenfeizhang/bandersnatch-glv&#34;&gt;[arkworks]&lt;/a&gt; and &lt;a href=&#34;https://github.com/Consensys/gnark/blob/master/std/algebra/native/twistededwards/scalarmul_glv.go&#34;&gt;[gnark]&lt;/a&gt; implementations for twisted Edwards). But one should be careful about some extra checks of the decomposition $s = s_0 + \lambda s_1 \mod r$ (not the SNARK modulus). The integers $s_0, s_1$ can possibly be negative in which case they will be reduced in-circuit modulo the SNARK field and not $r$.&lt;/p&gt;
&lt;h2 id=&#34;the-fake-glv-trick&#34;&gt;The fake GLV trick&lt;/h2&gt;
&lt;p&gt;Remember that we are proving that $s\cdot P = Q$ and not computing it. We can &amp;ldquo;hint&amp;rdquo; the result $Q$ and check in-circuit that $s\cdot P - Q = \mathcal{O}$. Now, if we can find $u,v \leq \sqrt{r}$ such that $v\cdot s = u \pmod r$ then we can check instead that
$$ (v\cdot s)\cdot P - v\cdot Q = \mathcal{O}$$
which is equivalent to
$$ u\cdot P - v\cdot Q = \mathcal{O}$$
The thing now is that $u$ and $v$ are &amp;ldquo;small&amp;rdquo; and we can, similarly to the GLV algorithm, halve the size of the double-and-add loop and apply the Strauss-Shamir trick.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Solution&lt;/strong&gt;: running the half-GCD algorithm (i.e. running GCD half-way) is sufficient to find $u$ and $v$. We can apply the exact same trick for finding the lattice basis as in the GLV paper (Sec. 4). For completeness we recall the algorithm hereafter.
We apply the extended Euclidean algorithm to find the greatest common divisor of $r$ and $s$ (This gcd is 1 since $r$ is prime.) The algorithm produces a sequence of equations
$$w_i \cdot r + v_i \cdot s = u_i$$
for $i = 0, 1, 2, \dots$  where $w_0 = 1, v_0 = 0, u_0 = r, w_1 = 0, v_1 = 1, u_1 = s$, and $u_i \geq 0$ for all $i$. We stop at the index $m$ for which $u_m \geq \sqrt{r}$ and take $u = u_{m+1}$ and $v = -v_{m+1}$.
&lt;em&gt;Note:&lt;/em&gt; By construction $u$ is guaranteed to be a positive integer but $v$ can be negative, in which case it would be reduced in-circuit modulo the SNARK modulus and not $r$. To circumvent this we return in the hint $u$, $v$ and a $\texttt{b}=1$ if $v$ is negative and $\texttt{b}=0$ otherwise. In-circuit we negate $Q$ instead when $\texttt{b}=1$.&lt;/p&gt;
&lt;h3 id=&#34;implementation&#34;&gt;Implementation&lt;/h3&gt;
&lt;p&gt;A generic implementation in the gnark library is available at &lt;a href=&#34;https://github.com/Consensys/gnark/feat/fake-GLV&#34;&gt;gnark.io (feat/fake-GLV branch)&lt;/a&gt;. For Short Weierstrass (e.g. P256) look at the &lt;code&gt;scalarMulFakeGLV&lt;/code&gt; &lt;a href=&#34;https://github.com/Consensys/gnark/blob/62c89cb10cff1413e9d68cce054c7e711d04c726/std/algebra/emulated/sw_emulated/point.go#L1263&#34;&gt;method&lt;/a&gt; in the emulated package and for twisted Edwards (e.g. Bandersnatch/Jubjub) look at the &lt;code&gt;scalarMulFakeGLV&lt;/code&gt; &lt;a href=&#34;https://github.com/Consensys/gnark/blob/62c89cb10cff1413e9d68cce054c7e711d04c726/std/algebra/native/twistededwards/point.go#L261&#34;&gt;method&lt;/a&gt; in the native package.&lt;/p&gt;
&lt;h4 id=&#34;benchmark&#34;&gt;Benchmark&lt;/h4&gt;
&lt;p&gt;The best algorithm to implement scalar multiplication in a non-native circuit (i.e. circuit field ≠ curve field) when an efficient endomorphism is &lt;em&gt;not&lt;/em&gt; available is an adaptation of &lt;a href=&#34;https://www.iacr.org/archive/ches2007/47270135/47270135.pdf&#34;&gt;[Joye07]&lt;/a&gt; (implemented in &lt;a href=&#34;https://github.com/Consensys/gnark/blob/fdb2b0de422b1c4fc5c6d08e81e788095ac818a6/std/algebra/emulated/sw_emulated/point.go#L748&#34;&gt;gnark here&lt;/a&gt;).
Next we compare this scalar multiplication with our fake GLV in a PLONKish vanilla (i.e. no custom gates) circuit (scs) over the BN254 curve (Ethereum compatible). We also give benchmarks in R1CS.&lt;/p&gt;
&lt;table&gt;
  &lt;thead&gt;
      &lt;tr&gt;
          &lt;th style=&#34;text-align: left&#34;&gt;P-256&lt;/th&gt;
          &lt;th style=&#34;text-align: center&#34;&gt;Old (Joye07)&lt;/th&gt;
          &lt;th style=&#34;text-align: right&#34;&gt;New (fake GLV)&lt;/th&gt;
      &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
      &lt;tr&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;$[s]P$&lt;/td&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;738,031 scs / 186,466 r1cs&lt;/td&gt;
          &lt;td style=&#34;text-align: right&#34;&gt;385,412 scs / 100,914 r1cs&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;ECDSA verification&lt;/td&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;1,135,876 scs / 293,814 r1cs&lt;/td&gt;
          &lt;td style=&#34;text-align: right&#34;&gt;742,541 scs / 195,266 r1cs&lt;/td&gt;
      &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;blockquote&gt;
&lt;p&gt;Note here that the old ECDSA verification uses Strauss-Shamir trick for computing $[s]P+[t]Q$ while the new version is merely two fake GLV multiplications and an addition.&lt;/p&gt;&lt;/blockquote&gt;
&lt;h4 id=&#34;comparison&#34;&gt;Comparison&lt;/h4&gt;
&lt;p&gt;&lt;a href=&#34;https://www.p256wallet.org/&#34;&gt;p256wallet.org&lt;/a&gt; is an ERC-4337 smart contract wallet that leverages zk-SNARKs for WebAuthn and P-256 signature verification. It uses &lt;a href=&#34;https://github.com/privacy-scaling-explorations/circom-ecdsa-p256&#34;&gt;PSE/circom-ecdsa-p256&lt;/a&gt; to generate the webAuthn proof, and underneath &lt;a href=&#34;https://github.com/privacy-scaling-explorations/circom-ecdsa-p256&#34;&gt;PSE/circom-ecdsa-p256&lt;/a&gt; to generate the ECDSA proof on P-256 curve. The github README reports &lt;code&gt;1,972,905 R1CS&lt;/code&gt;. Compiling our circuit in R1CS results in &lt;strong&gt;&lt;code&gt;195,266 R1CS&lt;/code&gt;&lt;/strong&gt;. This is more than a &lt;strong&gt;10x&lt;/strong&gt; reduction, which is not only due to the fake GLV algorithm but also to optimized non-native field arithmetic in gnark.&lt;/p&gt;
&lt;h4 id=&#34;other-curves&#34;&gt;Other curves&lt;/h4&gt;
&lt;p&gt;Similar results are noticed for other curves in short Weirstrass, e.g. P-384 and STARK curve:&lt;/p&gt;
&lt;table&gt;
  &lt;thead&gt;
      &lt;tr&gt;
          &lt;th style=&#34;text-align: left&#34;&gt;P-384&lt;/th&gt;
          &lt;th style=&#34;text-align: center&#34;&gt;Old (Joye07)&lt;/th&gt;
          &lt;th style=&#34;text-align: right&#34;&gt;New (fake GLV)&lt;/th&gt;
      &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
      &lt;tr&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;$[s]P$&lt;/td&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;1,438,071 scs&lt;/td&gt;
          &lt;td style=&#34;text-align: right&#34;&gt;782,674 scs&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;ECDSA verification&lt;/td&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;2,174,027 scs&lt;/td&gt;
          &lt;td style=&#34;text-align: right&#34;&gt;1,419,929 scs&lt;/td&gt;
      &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;table&gt;
  &lt;thead&gt;
      &lt;tr&gt;
          &lt;th style=&#34;text-align: left&#34;&gt;STARK curve&lt;/th&gt;
          &lt;th style=&#34;text-align: center&#34;&gt;Old (Joye07)&lt;/th&gt;
          &lt;th style=&#34;text-align: right&#34;&gt;New (fake GLV)&lt;/th&gt;
      &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
      &lt;tr&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;$[s]P$&lt;/td&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;727,033 scs&lt;/td&gt;
          &lt;td style=&#34;text-align: right&#34;&gt;380,210 scs&lt;/td&gt;
      &lt;/tr&gt;
      &lt;tr&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;ECDSA verification&lt;/td&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;1,137,459 scs&lt;/td&gt;
          &lt;td style=&#34;text-align: right&#34;&gt;732,131 scs&lt;/td&gt;
      &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;p&gt;and also in twisted Edwards e.g. Jubjub vs. Bandersnatch:&lt;/p&gt;
&lt;table&gt;
  &lt;thead&gt;
      &lt;tr&gt;
          &lt;th style=&#34;text-align: left&#34;&gt;Jubjub&lt;/th&gt;
          &lt;th style=&#34;text-align: center&#34;&gt;Old (2-bit double-and-add)&lt;/th&gt;
          &lt;th style=&#34;text-align: right&#34;&gt;New (fake GLV)&lt;/th&gt;
      &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
      &lt;tr&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;$[s]P$&lt;/td&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;5,863 scs / 3,314 r1cs&lt;/td&gt;
          &lt;td style=&#34;text-align: right&#34;&gt;4,549  scs / 2,401 r1cs&lt;/td&gt;
      &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;table&gt;
  &lt;thead&gt;
      &lt;tr&gt;
          &lt;th style=&#34;text-align: left&#34;&gt;Bandersnatch&lt;/th&gt;
          &lt;th style=&#34;text-align: center&#34;&gt;Old (GLV)&lt;/th&gt;
          &lt;th style=&#34;text-align: right&#34;&gt;New (fake GLV)&lt;/th&gt;
      &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
      &lt;tr&gt;
          &lt;td style=&#34;text-align: left&#34;&gt;$[s]P$&lt;/td&gt;
          &lt;td style=&#34;text-align: center&#34;&gt;4,781 scs /  2,455 r1cs&lt;/td&gt;
          &lt;td style=&#34;text-align: right&#34;&gt;4,712 scs / 2,420 r1cs&lt;/td&gt;
      &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;
&lt;blockquote&gt;
&lt;p&gt;EDIT: Thanks to Ben Smith for reporting that a similar idea was proposed in [SAC05:ABGL+] for ECDSA verification. We note that, in our context, the trick applies to a single scalar multiplication and that the half GCD is free through the hint.&lt;/p&gt;&lt;/blockquote&gt;
</description>
    </item>
    
    <item>
      <title>ZPrize competition 2022</title>
      <link>/post/zprize/</link>
      <pubDate>Tue, 04 Apr 2023 00:00:00 +0000</pubDate>
      <guid>/post/zprize/</guid>
      <description>&lt;blockquote&gt;
&lt;p&gt;Zero-knowledge cryptography is a groundbreaking new technology enabling privacy, interoperability, and scalability for Web 3.0 protocols and applications. Like the DARPA Grand Challenge, select teams will compete for monetary prizes spanning a range of categories. Over $7M in prize money has been committed, along with token grants from sponsoring projects.&lt;/p&gt;
&lt;p&gt;All winning submissions will become open-source libraries for the benefit of all. We hope this foundation can support the next generation of decentralized protocols and applications to enable secure, interoperable, and scalable applications for the next-generation web.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;With Gautam Botrel from Consensys, we participated in the inaugural edition of ZPrize (2022) in the open division: &amp;ldquo;ACCELERATING MSM ON MOBILE&amp;rdquo; as the gnark team. Our submission resulted in a &lt;strong&gt;4.2x speedup&lt;/strong&gt; over the baseline and won the &lt;strong&gt;first place&lt;/strong&gt;. The prize was &lt;strong&gt;$259,147&lt;/strong&gt;.&lt;/p&gt;
&lt;h2 id=&#34;accelerating-msm-on-mobile&#34;&gt;ACCELERATING MSM ON MOBILE&lt;/h2&gt;
&lt;blockquote&gt;
&lt;p&gt;Proving on mobile devices is a transformative technology for applications including private transactions, self-sovereign identity, and scalable computation. Multi-scalar multiplication (MSM) is a core operation for producing zkSNARKs, and it is the primary bottleneck and barrier for deployment of proving on mobile. This prize will focus on minimizing latency of computing MSM in native mobile applications.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;The goal was to write the fastest MSM over BLS12-377 curve on a mobile device (Samsung Galaxy A13 5G). The specification details can be found &lt;a href=&#34;https://assets.website-files.com/625a083eef681031e135cc99/6305a48d25fb8f385a8da446_mobile-msm.pdf&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Our submission was written in Go, and derived from the &lt;a href=&#34;https://github.com/Consensys/gnark-crypto&#34;&gt;gnark-crypto&lt;/a&gt; project.
On the target device, for a random BLS12-377 G1 MSM ($n = 2^{16}$), we measured:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;~2309ms for the reference benchmark&lt;/li&gt;
&lt;li&gt;~509ms for our submission&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This is a &lt;strong&gt;-77.9% optimisation&lt;/strong&gt;.&lt;/p&gt;
&lt;h2 id=&#34;code-and-techniques&#34;&gt;Code and techniques&lt;/h2&gt;
&lt;p&gt;The code can be found on github &lt;a href=&#34;https://github.com/gbotrel/zprize-mobile-harness&#34;&gt;here&lt;/a&gt; under Apache-2 or MIT license.&lt;/p&gt;
&lt;p&gt;We experimented several approaches; here is a description of the key findings for the final ones:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;It uses our in-house &lt;code&gt;gnark-crypto/bls12377&lt;/code&gt; package, which out of the box performs very well compared to the zprize baseline. The MSM algorithm is described in &lt;a href=&#34;https://eprint.iacr.org/2022/1400.pdf&#34;&gt;this paper&lt;/a&gt; (to appear in TCHES, Issue 3) and the Go code is documented. We introduced a bls12-377 algorithmic optimization; the &amp;ldquo;bucket/pippenger&amp;rdquo; method now uses an optimized twisted edwards extended cordinate system, resulting in a significant performance improvement (~30% on some target).&lt;/li&gt;
&lt;li&gt;We perform a static build targetting a 64bit arm linux architecture, which allows without a complicated build procress to run 64bit code on the target device. We copy the output in the armv7 (32bit) destination folder; in a production deployment, Java calling code must at runtime check for the actual CPU architecture and switch to a fallback if it&amp;rsquo;s 32bit (outside of the scope of the challenge). Note that while the submission spawn a process at each msm call, other ways may turn out more efficient (allocate the verifying key on the stack, communicate with the process with unix sockets, &amp;hellip;).&lt;/li&gt;
&lt;li&gt;We hand tuned the field arithmetic for the Multiplication targetting the arm64 architecture. Our pure-go version performed better than the arm assembly one, and resulted in a ~20% speed up on some platforms compared to existing version in gnark-crypto.&lt;/li&gt;
&lt;li&gt;We implemented and optimized a dedicated Squaring algorithm (rather than calling the Multiplication as in gnark-crypto) following our previous work &lt;a href=&#34;https://hackmd.io/@gnark/modular_multiplication&#34;&gt;https://hackmd.io/@gnark/modular_multiplication&lt;/a&gt;  (also described in the TCHES paper), which resulted in significant perf improvement on the target device. This is not used in the twisted edwards extended MSM, only in the parameterized Jacobian version which uses Affine points as input (branch: buckets/jacobian, performance: ~600ms for $2^16$).&lt;/li&gt;
&lt;li&gt;For the target (arm64) we add ~40lines of arm assembly for a small function (&lt;code&gt;fp.Butterfly(a, b) -&amp;gt; a = a + b; b = a - b&lt;/code&gt;). The perf impact is ~5%, as it speeds up a bit the UnifiedMixedAdd point addition in the buckets (msm). The rest of the submission is compiled from pure Go code;&lt;/li&gt;
&lt;li&gt;On this device, our GPU experimentations were not promising.&lt;/li&gt;
&lt;li&gt;We raised an &lt;a href=&#34;https://github.com/golang/go/issues/54607&#34;&gt;issue&lt;/a&gt; to the Golang team. Once the fix is merged into the latest Golang compiler release, we might squeeze an extra 5-10% perf improvement.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2 id=&#34;results&#34;&gt;Results&lt;/h2&gt;
&lt;p&gt;The results were annouced on 04-04-2023 in this &lt;a href=&#34;https://www.zprize.io/blog/announcing-zprize-results&#34;&gt;blog post&lt;/a&gt;.













&lt;figure&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;../img/zprize-results.png&#34; &gt;
&lt;img src=&#34;../img/zprize-results.png&#34; alt=&#34;&#34; &gt;&lt;/a&gt;



&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;The main sponsor (Ocelot) authored a more detailed announcement for the specific Mobile division in &lt;a href=&#34;https://mirror.xyz/ocelotlabs.eth/QytYZQIaiA73abHeUj8NS0Mm5_f0fMptrZM70DvmeMc&#34;&gt;this post&lt;/a&gt;.













&lt;figure&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;../img/ocelot-results2.png&#34; &gt;
&lt;img src=&#34;../img/ocelot-results2.png&#34; alt=&#34;&#34; &gt;&lt;/a&gt;



&lt;/figure&gt;














&lt;figure&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;../img/ocelot-results1.png&#34; &gt;
&lt;img src=&#34;../img/ocelot-results1.png&#34; alt=&#34;&#34; &gt;&lt;/a&gt;



&lt;/figure&gt;
&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>ZK-PAR 0x01</title>
      <link>/post/zkpar1/</link>
      <pubDate>Thu, 15 Aug 2019 00:00:00 +0000</pubDate>
      <guid>/post/zkpar1/</guid>
      <description>&lt;p&gt;Once upon a time, the entire Universe was inside a bubble that was thousands of times smaller than a pinhead. It was hotter and denser than anything we can imagine. Then it suddenly exploded. The Universe that we know was born. Time, space and matter all began with the Big Bang. In a fraction of a second, the Universe grew from smaller than a single atom to bigger than a galaxy. And it kept on growing at a fantastic rate. It is still expanding today.&lt;/p&gt;
&lt;p&gt;A biodiversity of species came to life. The total number of all species living on Earth estimates there are about 8.7 million species but the most important specie of all is one that, in the geological time scale, appeared recently. It is the human specie. So much happened on Earth before we came to call it home, but if we only focus on human life there is too much to narrate about.&lt;/p&gt;
&lt;p&gt;One of the main discoveries by humans was fire control, it was an important step in their culture. It allowed humans to cook food and get warmth and protection. But before that, making fire also allowed destructive use as humans used it to attack predators, insects and each others.&lt;/p&gt;
&lt;p&gt;Everyone knows this story but today I’m going to tell a similar story, as fascinating as this one. It is the story of elliptic curves. I’ll walk you through the pre- big bang and the post- big bang, I’ll show you the biodiversity of elliptic curves species and will present you to the specie used in cryptography, a.k.a. the Homo genus. Finally, we will go through a similar story to fire control that is pairing control.&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;I presented this story the 4th of July in Paris during ZK-PAR 0x01, the first Zero Knowledge meetup in the french capital. The meetups started in Tel-Aviv and then London and now Paris. They are intended for anyone interested in applied cryptography for privacy-preserving technology. The presentations are usually focussed on technical and practical aspects of this technology, notably its relation to blockchain technology. You can find more information and community discussions in the &lt;a href=&#34;https://www.facebook.com/groups/800441673459620/&#34;&gt;Facebook group&lt;/a&gt; and the &lt;a href=&#34;https://www.youtube.com/channel/UCl6oyLa4CblZRurgwZwpgPQ&#34;&gt;Youtube channel&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;ZK-PAR 0x01 hosted two speakers, Bastien Teinturier and myself. Bastien talked about anonymous payments in Bitcoin’s Lightning network and I invite you to watch his &lt;a href=&#34;https://www.youtube.com/watch?v=NM6WQkdjvYw&#34;&gt;video&lt;/a&gt; and go through his &lt;a href=&#34;https://www.facebook.com/download/1117672475092357/ZK-PAR%200x01%20-%20Anonymous%20Payments%20in%20the%20Lightning%20Network%20-%20Bastien%20Teinturier.pdf?av=1151079687&amp;amp;eav=AfZveN272Vcrq3TdwQjKZQC-0UB7Q5NrjhkqP49rdEu0fBxPOFQZ55mNASEgwNbfSFI&amp;amp;hash=AcruoDF8Elw9chP1&#34;&gt;slides&lt;/a&gt;. After that, my presentation was about this story of elliptic curves, or the story of life. Here is the &lt;a href=&#34;https://www.youtube.com/watch?v=bBWwOdGh2kw&amp;amp;fbclid=IwAR300GESe02Zn3npRvx8mZ746d1AdIV9kH-DAuYgkbhpz_hqLHAIqZTlnls&#34;&gt;video&lt;/a&gt; and the &lt;a href=&#34;https://www.facebook.com/download/526379754568293/ZK-PAR%200x01%20-%20The%20generation%20of%20elliptic%20curves%20in%20cryptography%20-%20Youssef%20El%20Housni.pdf?av=1151079687&amp;amp;eav=AfYj4dbTgsp8i9mVQ6lrwIAB-vVMX-EP3uNYm9UZgJxoiZ4vQnANPgB6jpLDNz63-VA&amp;amp;hash=Acow_XOTtNM_8fkj&#34;&gt;slides&lt;/a&gt;.&lt;/p&gt;













&lt;figure&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;../img/zkpar1_me.png&#34; &gt;
&lt;img src=&#34;../img/zkpar1_me.png&#34; alt=&#34;&#34; &gt;&lt;/a&gt;



&lt;/figure&gt;

&lt;p&gt;Thanks to the sponsors of ZK-PAR: Beam, Consensys and Bitcoin.fr&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>ZEXE - Zero-knowledge EXEcution</title>
      <link>/post/zexe/</link>
      <pubDate>Thu, 09 May 2019 00:00:00 +0000</pubDate>
      <guid>/post/zexe/</guid>
      <description>&lt;p&gt;ZK Study club is a learning group where people from the zero-knowledge/Blockchain community gather to study a specific topic. There have been so far nine sessions that discussed several cryptographic topics. The first four sessions broke down the ZK-STARKs, the fifth session was a deep dive into RSA accumulators, the sixth was about Sigma protocols, the seventh discussed the Fiat-Shamir heuristic and the eighth was about multi-party computations. The sessions are usually recorded and put available online:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=Q-Vl8pcP1fw&amp;amp;list=PLj80z0cJm8QHm_9BdZ1BqcGbgE-BEn-3Y&amp;amp;index=1&#34;&gt;session 1: ZK-STARKs&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=mBiWeF1TWzs&amp;amp;list=PLj80z0cJm8QHm_9BdZ1BqcGbgE-BEn-3Y&amp;amp;index=2&#34;&gt;seesion 2: ZK-STARKs&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=CQUXdQtpeoQ&amp;amp;list=PLj80z0cJm8QHm_9BdZ1BqcGbgE-BEn-3Y&amp;amp;index=3&#34;&gt;session 3: ZK-STARKs&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=GXlcFKSIQwY&amp;amp;list=PLj80z0cJm8QHm_9BdZ1BqcGbgE-BEn-3Y&amp;amp;index=4&#34;&gt;session 4: ZK-STARKs&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=tqqsbsAHJzs&amp;amp;list=PLj80z0cJm8QHm_9BdZ1BqcGbgE-BEn-3Y&amp;amp;index=5&#34;&gt;session 5: RSA accumulators&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=ptlgb3qi-b4&amp;amp;list=PLj80z0cJm8QHm_9BdZ1BqcGbgE-BEn-3Y&amp;amp;index=6&#34;&gt;session 6: Sigma protocols&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=k1_kGu1GGYo&amp;amp;list=PLj80z0cJm8QHm_9BdZ1BqcGbgE-BEn-3Y&amp;amp;index=6&#34;&gt;session 7: Fiat-Shamir heuristics&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;https://www.youtube.com/watch?v=VTd7C9EyRlU&amp;amp;list=PLj80z0cJm8QHm_9BdZ1BqcGbgE-BEn-3Y&amp;amp;index=8&#34;&gt;session 8: Multi-party computations&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The ninth session happened last Monday 6th May and was the first of a series about the recent paper called “&lt;a href=&#34;https://eprint.iacr.org/2018/962.pdf&#34;&gt;Zexe: Enabling Decentralized Private Computation&lt;/a&gt;” by Sean Bowe from ZCash, Alessandro Chiesa, Pratyush Mishra and Howard Wu from UC Berkeley, Matthew Green from Johns Hopkins University and Ian Miers from Cornell Tech. I had the chance to lead this session and discuss the paper’s ideas with wonderful community enthusiasts. The video can be found &lt;a href=&#34;https://www.youtube.com/watch?v=RItcNRChrzI&amp;amp;t=1732s&#34;&gt;here&lt;/a&gt; and the session’s notes &lt;a href=&#34;https://drive.google.com/drive/folders/1QMZFjYGKdgTaM_7MRK-rJ6l7OuvnMSnD&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Basically, the aim behind Zexe is to write private smart contract on a distributed ledger. Such a scheme can be constructed by doing offline computation and uploading a proof of correct execution to the ledger. The proof should be zero-knowledge, succinct and easy to verify. To do this, the paper introduces a new cryptographic primitive called decentralized private computation (DPC) and comes up with some efficient implementation tricks that range from zkSNARK optimization, recursive proof composition and a new set of elliptic curves.&lt;/p&gt;
&lt;p&gt;The starting point of Zexe is to extend &lt;a href=&#34;http://zerocash-project.org&#34;&gt;Zerocash protocol&lt;/a&gt; to more general token-based blockchains. This protocol provides a privacy-preserving version of Bitcoin-like blockchains via the use of zero-knowledge proofs (ZKP). To create a coin a user publishes a commitment and to consume it he publishes its unique serial number alongside some ZKP that the serial numbers belong to some old coins and that the commitments preserve the same total value. In Zexe, an integer value coin is a data payload record and the ZKP assures that an arbitrary function was applied to old records to create the new ones. The problem now is, if we want the function to be user-defined, how can we make sure it stays private, and if so, how can we isolate “malicious” functions from “honest” functions? One straightforward solution would be to add a ZKP that proves the same function was used; this basically boils down to using a Zerocash per function (i.e. per token) which results in a functionality limitation as one cannot do private cross-token swaps for instance and moreover the anonymity set would be limited to each each specific token history. Another solution would be to use a universal function on the ledger and embed user-defined functions within the data payload. To do this, we need a minimalist shared execution environment (some sort of an operating system) where different processes can be executed without violating the privacy of each. Zexe calls it records nano-kernel where a record is now: data payload, birth predicate for records creation, death predicate for records consumption, transaction memorandum for public input needed by the predicates and auxiliary input for private input. The problem now is, if the predicates are arbitrary functions, do we need a SNARK per predicate or a universal SNARK? While awesome research is being conducted to propose a universal SNARK like &lt;a href=&#34;https://eprint.iacr.org/2019/099.pdf&#34;&gt;Sonic&lt;/a&gt;, efficient implementations are yet to come. A solution to the cost of universality would be to do “a proof of a proof”, that is, generating a proof of the predicate and then generating another proof of the previous proof that will be verified on the ledger. This way, we need a single circuit on the ledger and a circuit per predicate offline.&lt;/p&gt;
&lt;p&gt;While &lt;a href=&#34;https://eprint.iacr.org/2014/595.pdf&#34;&gt;empirically proved via cycles of elliptic curves&lt;/a&gt;, recursive proofs are not efficient at 128-bit security level. In fact, a SNARK proof (i.e. in Groth16) is a set of points on an elliptic curve that has a subgroup of order $n$ so the generation has arithmetic in $\mathbb{F}_n$ whereas the verification uses p airing computations where most of the computations are on an extension of the field size $p$. This causes an arithmetic mismatch that results in an overhead of $log(p)$ when one wants to implement naïvely a verification circuit. The solution to this is to use a cycle of elliptic curves where the field size of one is equal to the subgroup order of the other and vice-versa. The only &lt;a href=&#34;https://arxiv.org/pdf/1803.02067.pdf&#34;&gt;pairing-friendly cycle of elliptic curves&lt;/a&gt; we know is the set of MNT4 and MNT6 curves that have a low embedding degree and thus are not quite efficient at 128-bit security level. In Zexe scheme, we need merely a proof of a proof so the authors came up with a chain of elliptic curves rather than a cycle, namely a &lt;a href=&#34;https://eprint.iacr.org/2006/372.pdf&#34;&gt;Cocks-pinch&lt;/a&gt; curve embedded over a &lt;a href=&#34;https://eprint.iacr.org/2006/372.pdf&#34;&gt;BLS&lt;/a&gt; curves that is highly 2-adic with respect to both the field size and the subgroup order.&lt;/p&gt;
&lt;p&gt;This is somewhat an overview of Zexe, but the paper includes more contributions such as delegating the generation of a proof to an untrusted worker (delegated DPC), minimizing operations over the (heavy) embedded cocks-pinch curve, optimizing the NP statements à la Zcash and more&amp;hellip;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Shamir Secret Sharing — The magic 3S Spell</title>
      <link>/post/sss/</link>
      <pubDate>Tue, 02 Apr 2019 00:00:00 +0000</pubDate>
      <guid>/post/sss/</guid>
      <description>&lt;blockquote&gt;
&lt;p&gt;“There are no more Horcruxes. It’s just you and me. Neither can live while the other survives, and one of us is about to leave for good…”
—Harry Potter and the Deathly Hallows, Chapter 36: The Flaw in the Plan.&lt;/p&gt;&lt;/blockquote&gt;
&lt;p&gt;The Horcrux hunt was a mission started by Albus Dumbeldore and given to Harry Potter to find all of Lord Voldemort’s remaining Horcruxes and destroy them. Obsessed with immortality from a young age, Lord Voldemort created a series of Horcruxes in an effort to prevent his death. A Horcrux is a vessel into which one places a piece of one’s soul to protect one from mortal death. Voldemort split his soul into 7 secret parts in a way that reconstruction is possible. It is widely believed that the process for Horcrux splitting involves a spell and a horrific act is performed after a murder has been committed, but this is not true. Voldemort invented this cover story to keep secret the very simple spell he used (a wizard patent for the technical term) — it is called the 3S spell.&lt;/p&gt;
&lt;p&gt;The 3S spell is nothing but a Shamir secret sharing scheme. In this scheme, a dealer (Voldemort) splits a secret (his soul) into multiple shares (Horcruxes) in a way that reconstruction is only possible when combining all of the shares or some sufficient fixed number of them. The spell uses some basic polynomial algebra magic (1st year at Hogwarts) and some finite field wizardry.&lt;/p&gt;
&lt;h2 id=&#34;basic-scheme&#34;&gt;Basic scheme&lt;/h2&gt;
&lt;p&gt;Let’s $s$ be the secret and $n$ the number of shares, a dealer can construct a secret sharing scheme where only $t &amp;lt; n$ custodians can reconstruct the secret $s$. He first generates a $t$-degree polynomial $P(X) = p_0 + p_1X + p_2X^2 + · · · + p_t X^t$ where $p_0$ is the secret $s$ and $p_1, p_2, \dots , p_t$ are chosen at random from the finite field we’re working in (e.g. $\mathbb{F}_31$ which means integers from 0 to 30). He then computes the points $v_1 = P(1), v_2 = P(2), \dots and v_n = P(n)$ and distributes these $n$ shares to the custodians. Any $t &amp;lt; n$ shares can reconstruct the polynomial $P$ with interpolation (e.g. &lt;a href=&#34;https://en.wikipedia.org/wiki/Lagrange_polynomial&#34;&gt;Lagrange interpolation&lt;/a&gt;) and recover the original secret $s = P(0)$. Note that any $t − 1$ shares would interpolate with high probability a false polynomial.&lt;/p&gt;













&lt;figure&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;../img/sss_wiki1.png&#34; data-caption=&#34;One can draw an infinite number of polynomials of degree 2 through 2 points. 3 points are required to define a unique polynomial of degree 2. This image is for illustration purposes only — Shamir’s scheme uses polynomials over a finite field, not re-presentable on a 2-dimensional plane (Wikipedia)&#34;&gt;
&lt;img src=&#34;../img/sss_wiki1.png&#34; alt=&#34;&#34; &gt;&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    One can draw an infinite number of polynomials of degree 2 through 2 points. 3 points are required to define a unique polynomial of degree 2. This image is for illustration purposes only — Shamir’s scheme uses polynomials over a finite field, not re-presentable on a 2-dimensional plane (&lt;a href=&#34;https://en.wikipedia.org/wiki/Shamir%27s_Secret_Sharing&#34;&gt;Wikipedia&lt;/a&gt;)
  &lt;/figcaption&gt;


&lt;/figure&gt;














&lt;figure&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;../img/sss_wiki2.png&#34; data-caption=&#34;This is a polynomial curve over a finite field — now the order of the polynomial has seemingly little to do with the shape of the graph (Wikipedia)&#34;&gt;
&lt;img src=&#34;../img/sss_wiki2.png&#34; alt=&#34;&#34; &gt;&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    This is a polynomial curve over a finite field — now the order of the polynomial has seemingly little to do with the shape of the graph (&lt;a href=&#34;https://en.wikipedia.org/wiki/Shamir%27s_Secret_Sharing&#34;&gt;Wikipedia&lt;/a&gt;)
  &lt;/figcaption&gt;


&lt;/figure&gt;

&lt;h2 id=&#34;verifiable-scheme&#34;&gt;Verifiable scheme&lt;/h2&gt;
&lt;p&gt;There are two problems with the basic scheme:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;A malicious custodian can submit a false share&lt;/li&gt;
&lt;li&gt;A malicious dealer can distribute false shares&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The first issue can be addressed by adding some fingerprint to the secret. This way, if a malicious custodian submit a false share, the reconstructed secret won’t be correct and the fingerprint lost. One way to do this is by concatenating the secret s with the hash of the last 31 bytes of s, i.e. s ← (s||sha256(s[: −32]). However, identifying the malicious custodian remains impossible in this approach.&lt;/p&gt;
&lt;p&gt;The solution to the second problem, can both identify a malicious dealer and a malicious custodian in the first scenario. A simple approach would be to publicly publish the hashes of shares but this might be impractical in some use-cases where the number of custodians increases quickly. In fact, each custodian will have a database of auxiliary information that may increases quickly over the time. A better approach was proposed by Feldman and uses homomorphic commitments.&lt;/p&gt;
&lt;h3 id=&#34;feldmans-approach&#34;&gt;Feldman’s approach:&lt;/h3&gt;
&lt;p&gt;In this approach, the dealer publishes the commitments of polynomial’s coefficients $p_0= s$ and $p_1, p_2, \dots, p_t$ that are homomorphic with respect to multiplication. Such a commitment is known to be a Pedersen’s commitment. Given a finite field of prime characteristic $p$ and a generator $g$, the dealer publishes $c_0 \equiv g^s \pmod p, c_1 \equiv g^{p_1} \pmod p, \dots$ and $c_t \equiv g^{p_t} \pmod p$. Given the commitments $c_i$ for $i \in [0, t]$, the is no way to retrieve the secret $s$ and the coefficients $p_1, p_2, \dots, p_t$ because of the hardness of the discrete logarithm problem. A custodian can verify that the share $v_i$ he was given by the dealer wasn’t tampered with thanks to the homomorphic property of Pedersen’s commitments. In fact,&lt;/p&gt;













&lt;figure&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;../img/sss_eq.png&#34; &gt;
&lt;img src=&#34;../img/sss_eq.png&#34; alt=&#34;&#34; &gt;&lt;/a&gt;



&lt;/figure&gt;

&lt;p&gt;This is basically the magic 3S spell that allowed Lord Voldemort to split his soul into 7 horcruxes. The process is rather simple that even Ronald Weasley can perform, but Tom Riddle invented the horrific-act-after-murder story to keep away wizardry newbies from reaching immortality.&lt;/p&gt;
&lt;p&gt;Yes, I ruined your childhood memories. Sorry Not Sorry.&lt;/p&gt;













&lt;figure&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;../img/sss_voldemort.jpg&#34; &gt;
&lt;img src=&#34;../img/sss_voldemort.jpg&#34; alt=&#34;&#34; &gt;&lt;/a&gt;



&lt;/figure&gt;

</description>
    </item>
    
    <item>
      <title>Zero-knowledge summit - ZK0x03</title>
      <link>/post/zk_summit_3/</link>
      <pubDate>Sat, 23 Mar 2019 00:00:00 +0000</pubDate>
      <guid>/post/zk_summit_3/</guid>
      <description>&lt;p&gt;On March 22nd 2019, I attended the third edition of &lt;a href=&#34;https://www.zeroknowledge.fm/summit&#34;&gt;zero-knowledge summit ZK0x03&lt;/a&gt; held at Berlin. The summit was organized by Anna Rose and Fredrik Harrysson from &lt;a href=&#34;https://www.zeroknowledge.fm&#34;&gt;zero-knowledge podcast&lt;/a&gt;, which is made for fellow developers and people looking to educate themselves on the inner workings of the blockchain zero-knowledge tech space. This one-day event focused on zero-knowledge topics, zkSNARK, MPCs, STARKs and blockchain scaling solutions featuring the following speakers:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Ahivu Levy (StarkWare Industries) discussing scalability with STARKs&lt;/li&gt;
&lt;li&gt;Harry Roberts (Ethsnarks) sharing the history of high-level programming languages for making zk proofs&lt;/li&gt;
&lt;li&gt;John &amp;lsquo;Tux&amp;rsquo; Pacific (Nucypher) on fully homomorphic encryption&lt;/li&gt;
&lt;li&gt;Jordi Baylina (Iden3) on Circom and Snarkjs&lt;/li&gt;
&lt;li&gt;Izaak Meckler (CODA Protocol) on the secrets of SNARK programming&lt;/li&gt;
&lt;li&gt;Alex Vlasov (Matter Labs) on scaling &amp;amp; privacy with zkSNARKs in Ethereum&lt;/li&gt;
&lt;li&gt;Aurélien Nicolas (QED-it, zkproofs.org) discussing zk standards&lt;/li&gt;
&lt;li&gt;Zachary Williamson (Aztec Protocol) on ERC-1724 confidential digital assets&lt;/li&gt;
&lt;li&gt;Igor Barinov (POA Network) on scaling with xDai and side chains&lt;/li&gt;
&lt;li&gt;Jonathan Levi (HACERA) on ZKPs for both permissioned and permissionless blockchains&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;There were also discussions on confidential transaction scheme based on 1-out-of-N proofs, GDPR and privacy of Zcash shielded transactions as well as deep-dive workshops on practical use and implementation of ZKPs, building a STARK with pen and paper and more. The program ran from 9:30 a.m. to 8 p.m. where talks were presented at two different filmed stages while roundtables and circle discussion happened on two other dedicated rooms. The full program can be found &lt;a href=&#34;https://docs.google.com/spreadsheets/d/1V90U-mVMWsbO1PzSxDVOSJ76_a9pCORJPJYfInWvOLA/edit#gid=0&#34;&gt;here&lt;/a&gt; and the playlist of videos &lt;a href=&#34;https://www.youtube.com/playlist?list=PLj80z0cJm8QHvg1ydi6rTEUK1SpxbtKnM&#34;&gt;here&lt;/a&gt;.&lt;/p&gt;
&lt;hr&gt;
&lt;p&gt;Since the program was running in parallel, I couldn’t make it to all the presentations so I chose 3 talks and 2 roundtables I was most interested in:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Talk 1: scalability first with STARK — Ahivu levy (StarkWare industries)&lt;/li&gt;
&lt;/ul&gt;













&lt;figure&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;../img/talk1.png&#34; data-caption=&#34;video of the talk&#34;&gt;
&lt;img src=&#34;../img/talk1.png&#34; alt=&#34;&#34; &gt;&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    &lt;a href=&#34;https://www.youtube.com/watch?v=H16nWlj3C_M&amp;amp;index=3&amp;amp;list=PLj80z0cJm8QHvg1ydi6rTEUK1SpxbtKnM&amp;amp;t=0s&#34;&gt;video of the talk&lt;/a&gt;
  &lt;/figcaption&gt;


&lt;/figure&gt;

&lt;p&gt;This talk was about scalability using STARKs — It was presented by Ahivu, the head product of StarkWare, a startup that leverages on STARK technology to improve blockchain scalability and privacy. The main takeaway is that they are planning to release their first product mid-april which is a decentralized exchange (DEX) engine on Ethereum. While STARKs can solve privacy on the blockchain as it is widely believed, Ahivu thinks that they are the best candidate to solve scalability thanks to the exponentially small verifier running time.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Talk 2: fully homomorphic encryption the road to secure computation — John Tux Pacific (NuCypher)&lt;/li&gt;
&lt;/ul&gt;













&lt;figure&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;../img/talk2.png&#34; data-caption=&#34;video of the talk&#34;&gt;
&lt;img src=&#34;../img/talk2.png&#34; alt=&#34;&#34; &gt;&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    &lt;a href=&#34;https://www.youtube.com/watch?v=_1qFoDEhHRY&amp;amp;index=6&amp;amp;list=PLj80z0cJm8QHvg1ydi6rTEUK1SpxbtKnM&amp;amp;t=0s&#34;&gt;video of the talk&lt;/a&gt;
  &lt;/figcaption&gt;


&lt;/figure&gt;

&lt;p&gt;This talk was about secure multiparty computation (SMPC), trusted execution evironments (TEE) and fully homomorphic encryption (FHE) with focus on the latter. It was presented by John who is a cryptography engineer at NuCypher, a startup that works mainly on proxy-reencryption and FHE to build privacy infrastructure for the blockchain. John started by presenting SMPC, TEE and FHE, and and then listed the pros and cons of each approach. Because FHE seems to be the ideal approach, he then exposed how research is aiming to address FHE cons.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Talk 3: Scaling and privacy with zkSNARKs in Ethereum — Alex Vlasov (Matter Labs)&lt;/li&gt;
&lt;/ul&gt;













&lt;figure&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;../img/talk3.png&#34; data-caption=&#34;video of the talk&#34;&gt;
&lt;img src=&#34;../img/talk3.png&#34; alt=&#34;&#34; &gt;&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    &lt;a href=&#34;https://www.youtube.com/watch?v=fSp2tyTtsEY&amp;amp;list=PLj80z0cJm8QHvg1ydi6rTEUK1SpxbtKnM&amp;amp;index=7&amp;amp;t=0s&#34;&gt;video of the talk&lt;/a&gt;
  &lt;/figcaption&gt;


&lt;/figure&gt;

&lt;p&gt;Although the title of this talk is “scaling and privacy with zkSNARKs in Etherem”, the presentation was mainly about the new zero-knowledge protocol called &lt;a href=&#34;https://eprint.iacr.org/2019/099.pdf&#34;&gt;SONIC&lt;/a&gt; and its comparison to the actual Groth16 zkSNARK protocol implemented in ZCash. The talk was presented by Alex who works at Matter Labs, a startup aiming to scale the blockchain using zero-knowledge proofs. &lt;a href=&#34;https://eprint.iacr.org/2019/099.pdf&#34;&gt;SONIC&lt;/a&gt; is a new ZK proving system that requires an updatable and universal trusted setup — that means unlike other SNARKs, &lt;a href=&#34;https://eprint.iacr.org/2019/099.pdf&#34;&gt;SONIC&lt;/a&gt; does not require a trusted setup for each circuit, but only a single setup for all circuits (up to a given circuit depth) and it never has to end, so it can be continuously secured by accumulating more contributions. To this point, Alex gave a nice comparison between usual SNARKs and &lt;a href=&#34;https://eprint.iacr.org/2019/099.pdf&#34;&gt;SONIC&lt;/a&gt;; imagine you are playing a card game and you want some trusted deck of cards, in SNARKs you shuffle the deck and then you pass it to other players who shuffle it again every time you start a new game, but in &lt;a href=&#34;https://eprint.iacr.org/2019/099.pdf&#34;&gt;SONIC&lt;/a&gt;s you only shuffle the deck once and then “clone” it every time you start a new game (this works for every game that requires the same number of cards or less ~circuit depth). For efficiency comparison, Groth16 is still better (0.6s vs 9s for a single proof and 3s vs 11.5s for a batch of 5 proofs — according to Alex benchmark) but we still need an efficient &lt;a href=&#34;https://eprint.iacr.org/2019/099.pdf&#34;&gt;SONIC&lt;/a&gt; implementation as in Bellman to compare apples to apples. The main takeaway is that &lt;a href=&#34;https://eprint.iacr.org/2019/099.pdf&#34;&gt;SONIC&lt;/a&gt;s are a real breakthrough that solve somewhat the SNARKs trusted setup issue. It is to mention that I discussed &lt;a href=&#34;https://eprint.iacr.org/2019/099.pdf&#34;&gt;SONIC&lt;/a&gt;s with Ariel Gabizon (former ZCash cryptographer who discovered the trusted setup counterfeiting bug in ZCash) after the talk and he believes that a lot of research is being conducted in this direction and more efficient protocols are likely to be proposed later this year.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Roundtable 1: GPU implementation of zksnark prover — Konstantin Panarin (Matter Lab)&lt;/li&gt;
&lt;/ul&gt;













&lt;figure&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;../img/roundtable1.png&#34; &gt;
&lt;img src=&#34;../img/roundtable1.png&#34; alt=&#34;&#34; &gt;&lt;/a&gt;



&lt;/figure&gt;

&lt;p&gt;This roundtable was animated by Konstantin from Matter Labs. He started by describing NVIDIA GPU architecture and code parallelization principles with examples, then he discussed how we can benefit from GPUs to speedup the proving step in Groth16 zkSNARKs. The most important part of the proving step (~60% of the computation time) is the multi-exponentiation and one way to do this efficiently is using &lt;a href=&#34;https://cr.yp.to/papers/pippenger.pdf&#34;&gt;Pippenger&lt;/a&gt; algorithm (ZCash by the way moved from Bos-Coster algortihm to &lt;a href=&#34;https://cr.yp.to/papers/pippenger.pdf&#34;&gt;Pippenger&lt;/a&gt; after Sapling activation). We discussed how the algorithm works and how it can be enhanced using NVIDIA GPUs keeping in mind that an enhancement should not only address the computation time but also the memory cost.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Roundtable 2: Building a STARK with pen and paper — Mathew Stevens and Micro Richter&lt;/li&gt;
&lt;/ul&gt;













&lt;figure&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;../img/roundtable2.jpg&#34; &gt;
&lt;img src=&#34;../img/roundtable2.jpg&#34; alt=&#34;&#34; &gt;&lt;/a&gt;



&lt;/figure&gt;

&lt;p&gt;This one was funny actually— we were 30 people at the beginning but only 10 stayed until the very end because of the heavy maths content. We deep dived into all the dirty details of the mathematical machinery behind zkSTARKS given a toy example (a Fibonacci sequence). The steps are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Arithmetic intermediate representation (AIR) to show a computation as an execution trace with algebraic registers and to create polynomial contraints,&lt;/li&gt;
&lt;li&gt;algebraic placement and routing (APR) to transform the AIR into functions that are Reed-Solomon codes if and only if the execution trace is a witness,&lt;/li&gt;
&lt;li&gt;Reed-Solomon proximity testing (RPT) to check that an APR witness is an actual Reed-Solomon code in an efficient way, and&lt;/li&gt;
&lt;li&gt;fast Reed-Solomon Interactive oracle proof of proximity (FRI) to efficiently check the proximity to the Reed-Solomon codes.&lt;/li&gt;
&lt;/ul&gt;
&lt;hr&gt;













&lt;figure&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;../img/panel.png&#34; &gt;
&lt;img src=&#34;../img/panel.png&#34; alt=&#34;&#34; &gt;&lt;/a&gt;



&lt;/figure&gt;

&lt;p&gt;The summit was closed by a park bench panel animated by Anna and Fredrik in a game form. Anyone from the audience can ask any question but if it turns out to be an opinion/remark then she/he is invited on stage to answer the upcoming questions. Here is a question I asked (which is actually an opinion according to Mrs Justice Anna):
“Zero-knowledge proofs (ZKP) like zkSNARKs or zkSTARKs are not proofs but arguments because the soundness is only computational and not statistical, so is it a mistake to call them proofs?”&lt;/p&gt;
&lt;p&gt;Besides the talks which were really interesting, this event was an opportunity to meet a lot of people from the broad ZKP/Blockchain community and to discuss technical details with sometimes the authors of some papers I’ve been scouring over the few last months. For this reason, I want to thank the organizers Anna and Fredrik for putting all of this together and especially Xavier De Boissieu and Quentin Drouot from EY for making my attendance possible.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Encryption using elliptic curves</title>
      <link>/post/encryption_ec/</link>
      <pubDate>Thu, 03 Jan 2019 00:00:00 +0000</pubDate>
      <guid>/post/encryption_ec/</guid>
      <description>&lt;p&gt;In my first post, we’ve seen that elliptic curves cryptography (ECC) was first introduced as a better alternative to public-key cryptography based on multiplicative groups of finite fields. In fact, ECC requires smaller keys compared to its finite field analog to provide equivalent security. Finite fields cryptosystems rely on the “hardness” of the discrete logarithm problem (DLP) to build cryptographic tools such as encryption (ElGamal), key exchange (Diffie-Hellman DH) and digital signature algorithms(DSA). Analogously, one expects to have ElGamal, DH and DSA counterparts thanks to the “hardness” of the equivalent elliptic curves discrete logarithm problem (ECDLP). However, it seems that only ECDH and ECDSA are popular. So, is there an ElGamal version for elliptic curves? Is direct encryption even possible with elliptic curves?&lt;/p&gt;
&lt;p&gt;The use of elliptic curves in cryptography was suggested independently by Neal Koblitz and Victor S. Miller in 1985. The main reason was that previous asymmetric approaches were subject to subexponential-time index calculus algorithms that solve the underlying hard problems, whereas no subexponential-time algorithms are known for the discrete logarithm problem in a (suitably chosen) elliptic curve. Moreover, for the most part the best available algorithms are ones that have nothing to do with the specific structure of the elliptic curve group, but rather would work with essentially the same running time on any group. Such algorithms are said to be “generic”. In his &lt;a href=&#34;https://www.ams.org/journals/mcom/1987-48-177/S0025-5718-1987-0866109-5/S0025-5718-1987-0866109-5.pdf&#34;&gt;paper&lt;/a&gt;, Koblitz suggested an encryption algorithm similar to ElGamal but it needed an invertible function to map plaintexts to points on an elliptic curve which made the scheme a bit impractical. The algorithm works as follows:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;We set up an elliptic curve $E$ over a finite field $\mathbb{F}_p$ and a point $P$ of order $N$.&lt;/li&gt;
&lt;li&gt;We need a public known invertible function $f$ that maps messages $m$ to points $P_m$ on $E$.&lt;/li&gt;
&lt;li&gt;We choose a random secret key $x \in [1,N-1]$ and publish the point $Y=xP$ as public key.&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Encryption&lt;/em&gt;: We choose a random integer $k \in [1,N-1]$, then calculate $C_1=kP$, $C_2=kY$ and $P_m=f(m)$. The ciphertext is the tuple $(C_1, C_2+P_m)$.&lt;/li&gt;
&lt;li&gt;&lt;em&gt;Decryption&lt;/em&gt;: From the ciphertext $(C, D)$ we calculate $C&amp;rsquo;=xC$ and retrieve the point $P_m$ with $P_m=D-C&amp;rsquo;$ ($=k(xP)+P_m-x(kP)$). Finally, we recover the message $m$ with $f^{-1}(P_m)$.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Basically, this is how we can do encryption on the elliptic curve but for real-world encryption this is somehow impractical because of the required invertible point mapping. One way to do it is interpreting the message as the $X$ coordinate of a curve point and computing a matching $Y$ coordinate. This has two drawbacks:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;First, only about half of the $X$ values can be the first coordinate of a curve point and&lt;/li&gt;
&lt;li&gt;second, one needs to compute a modular quadratic residue ($Y^2=X^3+aX+b$) to find the $Y$. This is not trivial and requires using &lt;a href=&#34;https://en.wikipedia.org/wiki/Tonelli%E2%80%93Shanks_algorithm&#34;&gt;Tonelli-Shanks algorithm&lt;/a&gt;.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;So, for things to work, some variability (some bits which can be adjusted until a possible $X$ is reached) would be needed and since the size of the message would be severely limited (no bigger than $p$) this is hardly worthwhile.&lt;/p&gt;
&lt;p&gt;For these reasons, direct encryption using elliptic curve is not practical but one can use hybrid encryption instead. That is, using ECDH to produce a shared secret value that will be used as a secret for some symmetric encryption algorithm (e.g. AES). This is called Elliptic Curve Integrated Encryption Scheme (ECIES).&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Apple primes</title>
      <link>/post/apple_primes/</link>
      <pubDate>Tue, 06 Nov 2018 00:00:00 +0000</pubDate>
      <guid>/post/apple_primes/</guid>
      <description>&lt;p&gt;What does this title mean?&lt;/p&gt;
&lt;p&gt;Well, last week (October 30th, 2018), Apple published a &lt;a href=&#34;https://support.apple.com/fr-fr/HT209192&#34;&gt;security update for iOS 12.1&lt;/a&gt; and &lt;a href=&#34;https://support.apple.com/fr-fr/HT209193&#34;&gt;macOS Mojave 10.14.1&lt;/a&gt; that addresses an issue existing in the method for determining prime numbers. This method was implemented in Apple’s crytptographic library CoreCrypto which is used in many different cryptographic applications. Martin Albrecht, Jake Massimo and Kenny Paterson of Royal Holloway and Juraj Somorovsky of Ruhr University were issued the CVE-2018–4398 for discovering the pitfall. The full academic paper can be found &lt;a href=&#34;https://eprint.iacr.org/2018/749.pdf&#34;&gt;here&lt;/a&gt;. According to the paper, an attacker may be able to exploit a weakness in the primality test to incorrectly identify prime numbers.&lt;/p&gt;
&lt;p&gt;So what are prime numbers and why they are used in cryptography? How to efficiently test the primality of a number? and what would be the impact if composite numbers are incorrectly declared primes (Apple primes)?&lt;/p&gt;
&lt;h2 id=&#34;prime-numbers&#34;&gt;Prime numbers&lt;/h2&gt;
&lt;p&gt;A prime number is a positive integer that has exactly two positive integer factors, 1 and itself. For example, if we list the factors of 28, we have 1, 2, 4, 7, 14, and 28. That’s six factors. If we list the factors of 29, we only have 1 and 29. That’s two factors. So we say that 29 is a prime number, but 28 isn’t. Primes are central in number theory because of the fundamental theorem of arithmetic: every natural number greater than 1 is either a prime itself or can be factorized as a product of primes that is unique up to their order.&lt;/p&gt;
&lt;p&gt;There are infinitely many primes (Euclid gave a simple proof by contradiction or you can check more recent proofs using &lt;a href=&#34;https://en.wikipedia.org/wiki/Proof_of_the_Euler_product_formula_for_the_Riemann_zeta_function&#34;&gt;Euler product for the Riemann zeta function&lt;/a&gt; or the irrationality of &lt;a href=&#34;https://en.wikipedia.org/wiki/Leibniz_formula_for_%CF%80&#34;&gt;$\pi$ and Leibniz formula&lt;/a&gt;) but no known simple formula separates them from composite numbers.&lt;/p&gt;
&lt;p&gt;A deterministic straightforward method to check if an integer $p$ is prime is to test whether $p$ is a multiple of any integer between $2$ and $\sqrt{p}$, but this method or any deterministic approach remains very slow when dealing with big numbers.&lt;/p&gt;
&lt;h2 id=&#34;primality-tests&#34;&gt;Primality tests&lt;/h2&gt;
&lt;p&gt;Many popular primality tests are probabilistic tests because they provide provable bounds on the probability being fooled by a composite number. These tests use, apart from the tested number, some other numbers (witnesses) which are chosen at random; the usual randomized primality tests never report a prime number as composite, but it is possible for a composite number to be reported as prime. The probability of error can be reduced by repeating the test with several independently chosen values of witnesses .
The basic structure of randomized primality tests is as follows:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;Randomly pick a number .&lt;/li&gt;
&lt;li&gt;Check some equality (corresponding to the chosen test) involving and the given number . If the equality fails to hold true, then is a composite number and the test stops.&lt;/li&gt;
&lt;li&gt;Repeat from step 1 until the required accuracy is achieved.
After one or more iterations, if is not found to be a composite number, then it can be declared probably prime.&lt;/li&gt;
&lt;/ol&gt;
&lt;h2 id=&#34;fermat-primality-test&#34;&gt;Fermat Primality Test&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Fermat&amp;rsquo;s Little Theorem&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;If $p$ is as prime number and $a$ is a positive integer less than $p$, then the remainder of $a^{p-1}$ devising by $p$ is $1$ i.e. $a^{p-1} \equiv 1 \pmod p$&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Test Algorithm&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;If $p$ is the number which we want to test for primality, then we could randomly choose $a$, such that $a &amp;lt; p$ and then calculate $a^{p-1} \equiv \pmod p$. If the result is not $1$, then by Fermat’s Little Theorem $p$ cannot be prime. What if that is not the case? We can choose another $a$ and then do the same test again. We could stop after some number of iterations and if the result is always $1$ in each of them, then we can state that is probably prime. The more iterations we do, the higher is the probability that our result is correct.&lt;/p&gt;
&lt;h2 id=&#34;miller-rabin-primality-test&#34;&gt;Miller-Rabin Primality Test&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Key Ideas
&lt;ol&gt;
&lt;li&gt;Fermat’s Little Theorem.&lt;/li&gt;
&lt;li&gt;If $p$ is prime and $x^2 \equiv 1 \pmod p$, then $x \equiv 1$ or $-1 \pmod p$&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The number we want to test its primality is necessarily odd, then $p-1$ is even and we can write $p-1 = 2^s d$ where $d$ is an odd number and $d ≥ 0$.&lt;/p&gt;
&lt;p&gt;If $p$ is prime, then either $a^d \equiv 1 \pmod p$ as in this case, repeated squaring from $a^d$ will always yield $1$, so $a^{p-1} \pmod p$ will be $1$; or $a^{2^r d} \equiv -1 \pmod p$ for some $r$ such that $0 \leq r \leq s$, as repeated squaring from it will always yield $1$ and finally $a^{p-1} \equiv 1 \pmod p$. If none of these hold true, $a^{p-1}$ will not be $1$ for any prime number (otherwise there will be a contradiction with fact #2).&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Test Algorithm&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Let be $p$ the given number which we have to test. First we rewrite $p-1$ as $2^s d$. Now we pick some in range and then check whether or for . If both of them fail, then is definitely composite. Otherwise is probably prime. We can choose another and repeat the same test to reduce the probability of error.&lt;/p&gt;
&lt;hr&gt;
&lt;h2 id=&#34;apples-pitfall&#34;&gt;Apple’s pitfall&lt;/h2&gt;
&lt;p&gt;In number theory, a Carmichael number is a composite number $n$ which satisfies the modular arithmetic congruence relation $a^{p-1} \equiv 1 \pmod p$ for all integers $a$ which are coprime to $n$, i.e. a composite number that satisfies Fermat’s test. Robert Carmichael found the first and smallest such number, 561, which explains the name &amp;ldquo;Carmichael number&amp;rdquo;. Indeed, $561=3 \times 11 \times 17$ and $a^{560} \equiv 1 \pmod{561}$ for all $a$ coprime to $561$.&lt;/p&gt;
&lt;p&gt;Like the Fermat, the Rabin-Miller test has Carmichael numbers (choices of $a$ for which the test declares a composite integer to be a probable prime) but there are fewer. It turns out for any composite $n$, including Carmichael numbers, the probability $n$ passes the Miller-Rabin test is at most 1/4 (on average it is significantly less.) Thus the probability $n$ passes several runs decreases exponentially. However, the bases $a$ should be chosen randomly so an attacker wouldn’t be able to find Carmichael numbers with respect to these bases.&lt;/p&gt;
&lt;p&gt;In corecrypto library, Apple performs $t &amp;lt; 256$ rounds of Miller-Rabin testing, selecting the bases incrementally from a &lt;code&gt;hard-coded&lt;/code&gt; list of the first 256 primes. When performing, for instance, $t = 32$ rounds of testing, the probability of a false prime classification is estimated as 1/$2^{64}$. However, since the bases $a$ generation is deterministic, an attacker should be able to find composite numbers that fool the test. This was done in the &lt;a href=&#34;https://eprint.iacr.org/2018/749.pdf&#34;&gt;paper&lt;/a&gt; using the method described in Arnault, F &amp;ldquo;Constructing Carmichael numbers which are strong pseudoprimes to several bases&amp;rdquo; paper. An example of such a composite 1024-bit number of the form $n=p \times q \times r$ is given below:&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;n = 105216055594390884840438324972769319399722594046651360392070071794973423530188471087867855419188813164954561140227145977855514336985746250989366318940490798583710597151720075427387437940535767395296272532149397065590267303873620351321073058502920032770522836726669005262088263964215455869031740912313201227043
&lt;/code&gt;&lt;/pre&gt;&lt;p&gt;with&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;p = 123282949929736752510916282638002560328626287433241467864741378859343760091491850110380631340085554443
q = 28724927333628663335043493854654596556569924971945262012484741274227096101317601075718687102239934184987
r = 29711190933066557355130824115758617039198935271411193755402672305101846182049535876601732152960618620523
&lt;/code&gt;&lt;/pre&gt;</description>
    </item>
    
    <item>
      <title>Secure Two-Party Computation (S2PC)</title>
      <link>/post/s2pc/</link>
      <pubDate>Mon, 22 Oct 2018 00:00:00 +0000</pubDate>
      <guid>/post/s2pc/</guid>
      <description>&lt;p&gt;Not to toot my own horn here but when I was in high school I used to be quite popular :). I was moreover one of the least shy people I know but when it came to girls, I was interested in, I suddenly turn to this timid shell of a person. This awkward version of a popular guy is not uncommon and the fear of rejection is the reason that rattles us to the core. I still remember this girl from my high school I’ve never talked to, because of that fear — let’s call her &lt;em&gt;Salma&lt;/em&gt; in the sequel (Any resemblance to actual persons, living or dead, is purely coincidental). No matter how much courage I’ve summoned and how firmly I’ve convinced myself I don’t care about the outcome, hearing no from &lt;em&gt;Salma&lt;/em&gt; would have hurt. A graceful no hurts a great deal less but a cruel no in public drives a knife through the male psyche.&lt;/p&gt;
&lt;p&gt;Growing up, I became a cryptographer and figured out a mathematical way to deal with such a situation. How can you make secure advances to &lt;em&gt;Salma&lt;/em&gt; ? Is there a way to securely guess the outcome ? or simply put, how can you avoid a dismissive no in public ? The solution uses &lt;a href=&#34;https://en.wikipedia.org/wiki/Garbled_circuit&#34;&gt;Yao’s Garbled circuits&lt;/a&gt; for secure two-party computation (S2PC).&lt;/p&gt;
&lt;p&gt;Given private inputs $x$ and $y$ and a public function $f$, this method enables two parties to securely compute the outcome $f(x,y)$ without revealing the secrets $x$ and $y$. A circuit is just a way to represent a computation consisting of just operations on bits, like AND, OR, NOT and a garbled circuit is a way to “encrypt a computation” that reveals only the output of the computation, but reveals nothing about the inputs or any intermediate values. Our situation makes the basic way to understand how the protocol works. Let the secret $x$ be 1 if I am interested in &lt;em&gt;Salma&lt;/em&gt; and 0 otherwise. Similarly, her secret $y$ is either 1 or 0. We want to securely compute a function that outputs 1 if we both are interested in each other and 0 otherwise — no one should be able to guess the inputs. A simple function would be an AND gate.&lt;/p&gt;













&lt;figure&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;../img/s2pc_tab1.png&#34; &gt;
&lt;img src=&#34;../img/s2pc_tab1.png&#34; alt=&#34;&#34; &gt;&lt;/a&gt;



&lt;/figure&gt;

&lt;p&gt;There are 4 possibilities in the truth table but only one is the actual reality. Next, we “garble” this circuit as follows: For each wire $x, y$ and z, we specify two random values corresponding to 0 and 1 and then we encrypt (using some symmetric cipher such as AES) the truth table by encrypting the output-wire key with the corresponding pair of input-wire keys. Which results in the Garbled Computation Table (GCT).&lt;/p&gt;













&lt;figure&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;../img/s2pc_tab2.png&#34; &gt;
&lt;img src=&#34;../img/s2pc_tab2.png&#34; alt=&#34;&#34; &gt;&lt;/a&gt;



&lt;/figure&gt;

&lt;p&gt;Given two input keys only one row of the GCT can be decrypted correctly. Next, we rearrange the GCT — so that no information is leaked — and send it to &lt;em&gt;Salma&lt;/em&gt; along with my input key. Note that, since the key is random, there is no way to associate it with the actual bit. At this point, she has the GCT and my input key but needs the key I have already associated to her input bit. But just like me, &lt;em&gt;Salma&lt;/em&gt; doesn’t want to reveal her secret (bit)! Neither want I to send her both keys, as she would be able to decrypt more than a GCT row. What we need here is a protocol in which a sender transfers one of potentially many pieces of information to a receiver, but remains oblivious as to what piece has been transferred. Fortunately, such a protocol exists and is called &lt;a href=&#34;https://en.wikipedia.org/wiki/Oblivious_transfer&#34;&gt;1-out-of-2 oblivious transfer (OT)&lt;/a&gt;. In the next section, I will present a simple 1–2 OT protocol but if you don’t know how RSA encryption works just skip this section since explaining it goes beyond the scope of this post.&lt;/p&gt;
&lt;h2 id=&#34;12-oblivious-transfer&#34;&gt;1–2 Oblivious Transfer&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Alice holds $m_0, m_1$, and an RSA key pair $(e, d, N)$. Bob holds the public key $(e, N)$ of Alice, $x \in {0,1}$ and wants $m_x$&lt;/li&gt;
&lt;li&gt;Alice generates random $x_0, x_1$ and sends them to Bob&lt;/li&gt;
&lt;li&gt;Bob chooses a random $k$, computes $v=y_x+k^e$ and sends $v$ to Alice.&lt;/li&gt;
&lt;li&gt;Alice computes $k_0=(v-x_0)^d$ and $k_1=(v-x_1)^d$, and sends $m_0&amp;rsquo;=m_0+k_0$ and $m_1&amp;rsquo;=m_1+k_1$ to Bob&lt;/li&gt;
&lt;li&gt;Bob computes $m_x=m_x&amp;rsquo;-k$ and learns nothing about $m&amp;rsquo; _{1-x}$&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Now, using 1–2 OT protocol, &lt;em&gt;Salma&lt;/em&gt; can have her input key without me knowing anything about her secret bit. At this point, we can decrypt the GCT row corresponding to our secrets and reveal securely the output value. If it is a 0, none is able to tell who rejected the other and if it is a 1… Jackpot!&lt;/p&gt;
&lt;p&gt;By and large, this is how we can do secure two-party computation. So, dear &lt;em&gt;Salma&lt;/em&gt;, if by any chance you’re reading my post, here is my secret key ;)&lt;/p&gt;
&lt;pre tabindex=&#34;0&#34;&gt;&lt;code&gt;0x3361736861206c6d616c69696969696b
&lt;/code&gt;&lt;/pre&gt;</description>
    </item>
    
    <item>
      <title>Why elliptic curves are called &#34;elliptic&#34; ?</title>
      <link>/post/ellipse/</link>
      <pubDate>Sun, 14 Oct 2018 00:00:00 +0000</pubDate>
      <guid>/post/ellipse/</guid>
      <description>&lt;p&gt;Every name tells a story. If you ask new parents &amp;ldquo;how did you choose your baby’s name?&amp;rdquo; sometimes the response will be a vague &amp;ldquo;Oh &lt;em&gt;she&lt;/em&gt; chose!&amp;rdquo; but most of the time there is a story behind, and it’s often a great story about going through dozens of possibilities until one clicked. It goes from &lt;em&gt;her&lt;/em&gt; favorite fictional character to &lt;em&gt;her&lt;/em&gt; favorite great-aunt, so the baby has to be called &lt;a href=&#34;https://en.wikipedia.org/wiki/Daenerys_Targaryen&#34;&gt;Khaleesi&lt;/a&gt;. Obviously.
In mathematics, it is no different. When mathematicians introduce their new baby to the world, they choose an appropriate name far from being random. In my last &lt;a href=&#34;https://yelhousni.github.io/post/why_ec/&#34;&gt;post&lt;/a&gt;, I have talked about elliptic curves and why they are used in cryptography. This triggered the question on why they are called &amp;ldquo;elliptic&amp;rdquo; even though they do not resemble ellipses in any way.&lt;/p&gt;













&lt;figure&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;../img/ec_vs_ellipse.png&#34; &gt;
&lt;img src=&#34;../img/ec_vs_ellipse.png&#34; alt=&#34;&#34; &gt;&lt;/a&gt;



&lt;/figure&gt;

&lt;p&gt;Elliptic curves are of cubic equations $y^2=x^3+ax+b$ while ellipses are of quadratic equations $x^2/a^2+y^2/b^2=1$. So, prima facie, there is no connection between them. But looking deeply into the history of elliptic curves, one finds out the connection.
In the 18th century it was natural to ask about the arc length of an ellipse. In fact, despite their similarity to circles, ellipses are quite different. For example, a circle’s circumference is given by $2 \pi r$ and its area by $\pi r^2$ where $r$ is the radius. It is remarkable how the constant $\pi$ relates the circumference to the area given the radius $r$. But things are not that easy when dealing with ellipses. Given $a$ and $b$ as the semi-radii, the area of an ellipse is $\pi ab$ but the circumference is a more difficult question. More generally, the arc length of ellipses is difficult to calculate and is given either by a hard integral or by a rather formidable series. This question led to the study of $\sqrt{f(x)}$ where $f(x)$ is a polynomial of degree 3 or 4. These functions cannot be described with familiar calculus functions and came to be known as elliptic integrals. For circles, $f(x)$ is a quadratic polynomial and we get &amp;ldquo;circular integrals&amp;rdquo; which are easy to handle. for example, we know that $\int dx / (\sqrt{1-x^2}) = \sin ^{-1} (x)$ and the inverse of the function, namely $\sin{x}$, is well studied and easy to deal with. Thus, circular integrals lead to the periodic trigonometric functions. Similarly, studying the inverse of elliptic integrals leads to some doubly periodic functions which came to be known as elliptic functions (let’s call them ℘(z) in the sequel, because ℘ looks nice). Furthermore, all the derivatives are doubly periodic with the same periods and satisfy a cubic differential equation. Now in calculus, you learn about parametric equations and how they can describe a curve. By a parameterization of a curve $C$, we mean a continuous bijection from a set of numbers to the set of all points on $C$. For example, letting $x=a \sin{t}$ and $y=b \cos{t}$ with $t \in [0, 2 \pi)$ gives a familiar parameterization of the standard ellipse $x^2/a^2+y^2/b^2=1$. In the same way, we see that setting $x=℘(z)$ and $y=℘’(z)$ gives a parameterization of the cubic curve known today as an elliptic curve.
Names are reservoirs of stories and this was the story behind elliptic curves’ name.&lt;/p&gt;
&lt;p&gt;One last thing before I forget, dear future son, if this post lives long enough so that you are reading it now, I am sure you will understand why I called you Jon Snow. But for now, you know nothing Jon Snow.&lt;/p&gt;













&lt;figure&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;../img/jon_snow.jpg&#34; &gt;
&lt;img src=&#34;../img/jon_snow.jpg&#34; alt=&#34;&#34; &gt;&lt;/a&gt;



&lt;/figure&gt;

</description>
    </item>
    
    <item>
      <title>Why do we use elliptic curves for cryptography?</title>
      <link>/post/why_ec/</link>
      <pubDate>Sun, 07 Oct 2018 00:00:00 +0000</pubDate>
      <guid>/post/why_ec/</guid>
      <description>&lt;p&gt;In the series of posts I am willing to write, I will try to answer technical questions I have been asking myself throughout my readings about Maths, cryptography and Blockchain. For many questions, I couldn’t find easily or completely the answer I was looking for. One of these questions I faced is: Why did we even consider using elliptic curves for cryptography ? The question is &amp;ldquo;Why&amp;rdquo; rather than &amp;ldquo;How&amp;rdquo;.
Elliptic curves are mathematical objects from the algebraic geometry and one should be normally surprised when discovering that such objects are used to encrypt data. In fact, elliptic curves are non-singular algebraic curves satisfying an equation of the form $y^3=x^3+ax+b$ (cf. figure 1).&lt;/p&gt;













&lt;figure&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;../img/ec.png&#34; data-caption=&#34;Figure 1: Examples of elliptic curves over $\mathbb{R}^2$&#34;&gt;
&lt;img src=&#34;../img/ec.png&#34; alt=&#34;&#34; &gt;&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    Figure 1: Examples of elliptic curves over $\mathbb{R}^2$
  &lt;/figcaption&gt;


&lt;/figure&gt;

&lt;p&gt;Well, that doesn’t help us a lot.. And since I started this post with a question you have the right to ask more questions: What do these mathy words mean? How did we get this equation? And why are they even called &amp;ldquo;elliptic&amp;rdquo; even though they do not resemble &amp;ldquo;ellipses&amp;rdquo; in any way ? Don’t worry I’ve asked myself these same questions and we’re going to deep dive into the answers in later posts. For now, let’s go back to the main question: Why do we use these curves to encrypt data?
To answer this we have to trace the evolution of cryptography over the years. The earliest known cryptographic schemes use a symmetric approach — that is using the same key for both encryption and decryption. A simple example of this approach and one of the oldest would be &lt;a href=&#34;https://en.wikipedia.org/wiki/Caesar_cipher&#34;&gt;&amp;ldquo;Caesar cipher&amp;rdquo;&lt;/a&gt; in which each letter in the plaintext is replaced by a letter some fixed number of positions down the alphabet. In this scheme the encryption/decryption key is the fixed number of positions that must be kept secret and known only to the communicating parties. This symmetric approach is still widely used today through many ciphers such as &lt;a href=&#34;https://en.wikipedia.org/wiki/Advanced_Encryption_Standard&#34;&gt;AES&lt;/a&gt;, &lt;a href=&#34;https://en.wikipedia.org/wiki/Blowfish_%28cipher%29&#34;&gt;Blowfish&lt;/a&gt; or &lt;a href=&#34;https://en.wikipedia.org/wiki/RC4&#34;&gt;RC4&lt;/a&gt; but the requirement of a secret symmetric key is still the main drawback.
Cryptographers have been then looking for innovative asymmetric approaches where the decryption key differs from the encryption one. That is said, they have been looking for algorithms where it is easy to derive the decryption key (public) given the encryption key (private) and difficult the other way around — or mathematically put, a function that is straightforward to compute and computationally hard to inverse. One of the first algorithms proposed and still widely used nowadays is the famous &lt;a href=&#34;https://en.wikipedia.org/wiki/RSA_%28cryptosystem%29&#34;&gt;RSA&lt;/a&gt; which relies on the hardness of the &amp;ldquo;factorization problem&amp;rdquo;. In fact, given two prime integers, it is easy to compute their multiplication but presumably hard to find the prime integers given the multiplication output. At this point you may (should) be asking why is it hard to factorize an integer and the answer is that there is no published algorithm that can do this in polynomial time (an algorithm is said to be of polynomial time if its running time is upper bounded by a polynomial expression in the size of the input for the algorithm). In fact, the best published asymptotic running time (on a classical computer, not a quantum one. Wait, quantum?) is for the general number field sieve (&lt;a href=&#34;https://en.wikipedia.org/wiki/General_number_field_sieve&#34;&gt;GNFS&lt;/a&gt;) algorithm which has a sub-exponential complexity. In short, integer factorization is &amp;ldquo;hard&amp;rdquo; in the sense of computational efficiency because &lt;a href=&#34;https://en.wikipedia.org/wiki/P_versus_NP_problem&#34;&gt;we haven’t found just yet a reason for it to be easy, and we can’t prove it is hard&lt;/a&gt;. All this to come to the point that integer factorization, in my opinion, has nothing to do with the unknown primes distribution as widely believed. It is true that the problem is built upon the &lt;a href=&#34;https://en.wikipedia.org/wiki/Fundamental_theorem_of_arithmetic&#34;&gt;fundamental theorem of arithmetic&lt;/a&gt; which states that every integer can be uniquely represented as the product of prime numbers but I think that the chaotic nature of primes distribution has no bearing on the problem. There’s no reason to expect that factorization would become even a bit easier by proving the &lt;a href=&#34;https://en.wikipedia.org/wiki/Goldbach%27s_conjecture&#34;&gt;Goldbach conjecture&lt;/a&gt;, the &lt;a href=&#34;https://en.wikipedia.org/wiki/Twin_prime&#34;&gt;twin primes conjecture&lt;/a&gt; or the &lt;a href=&#34;https://en.wikipedia.org/wiki/Riemann_hypothesis&#34;&gt;Riemann Hypothesis&lt;/a&gt; for examples. However, the problem becomes computationally easier (polynomial time) when using quantum computers to run &lt;a href=&#34;https://en.wikipedia.org/wiki/Shor%27s_algorithm&#34;&gt;Shor’s algorithm&lt;/a&gt; as we will see on a later post.
Another proposed asymmetric construction relies on the hardness of the &amp;ldquo;discrete logarithm&amp;rdquo; problem in cyclic groups. Given integers a and b in a carefully chosen group G, no efficient method is known for recovering the integer k such that $a=b^k$. In fact, the problem is quickly computable in a few special cases but in some cases there is not only no efficient algorithm known for the worst case, but the &lt;a href=&#34;https://en.wikipedia.org/wiki/Average-case_complexity&#34;&gt;average-case complexity&lt;/a&gt; can be shown to be about as hard as the worst case using &lt;a href=&#34;https://en.wikipedia.org/wiki/Random_self-reducibility&#34;&gt;random self-reducibility&lt;/a&gt;. So choosing the group G is critical and a popular choice that provides good security assumptions is large prime order subgroups of groups $\mathbb{Z}_p$. These groups were used to build several known cryptographic protocols such as &lt;a href=&#34;https://en.wikipedia.org/wiki/ElGamal_encryption&#34;&gt;ElGamal encrytpion&lt;/a&gt;, &lt;a href=&#34;https://en.wikipedia.org/wiki/Diffie%E2%80%93Hellman_key_exchange&#34;&gt;Diffie-Hellman (DH) key exchange&lt;/a&gt; and &lt;a href=&#34;https://en.wikipedia.org/wiki/Diffie%E2%80%93Hellman_key_exchange&#34;&gt;Digital Signature Algorithm (DSA)&lt;/a&gt;. However, using these groups requires large key sizes because of the sub-exponential &lt;a href=&#34;https://en.wikipedia.org/wiki/General_number_field_sieve&#34;&gt;GNFS&lt;/a&gt; algorithm as well. In fact, while computing discrete logarithms and factoring integers are distinct problems, both are special cases of the &lt;a href=&#34;https://en.wikipedia.org/wiki/Hidden_subgroup_problem&#34;&gt;hidden subgroup problem&lt;/a&gt; for finite Abelian groups and thus, for both, the most efficient approach remains &lt;a href=&#34;https://en.wikipedia.org/wiki/General_number_field_sieve&#34;&gt;GNFS&lt;/a&gt; on a classical computer and &lt;a href=&#34;https://en.wikipedia.org/wiki/Shor%27s_algorithm&#34;&gt;Shor’s algorithm&lt;/a&gt; on a quantum computer.
At this point, you may be thinking that somehow changing that group G from finite fields to elliptic curves may provide better security assumptions. You’re right! The best published algorithms to find discrete logarithms over elliptic curves are &lt;a href=&#34;https://en.wikipedia.org/wiki/Pollard%27s_rho_algorithm&#34;&gt;Pollard’s $\rho$&lt;/a&gt; or &lt;a href=&#34;https://en.wikipedia.org/wiki/Baby-step_giant-step&#34;&gt;baby-step-giant-step&lt;/a&gt; with a way better running time than &lt;a href=&#34;https://en.wikipedia.org/wiki/General_number_field_sieve&#34;&gt;GNFS&lt;/a&gt;. But wait, what is a discrete logarithm over elliptic curves? (you ask a lot of questions, huh?) Well, no worries, we will soon deep dive into all the machinery ;)&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
